<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: rust | The {pnk}f(eli)x Blog]]></title>
  <link href="http://blog.pnkfx.org/blog/categories/rust/atom.xml" rel="self"/>
  <link href="http://blog.pnkfx.org/"/>
  <updated>2021-04-27T17:11:52-04:00</updated>
  <id>http://blog.pnkfx.org/</id>
  <author>
    <name><![CDATA[Felix S. Klock II]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Road to TurboWish; Part 2: Stories]]></title>
    <link href="http://blog.pnkfx.org/blog/2021/04/27/road-to-turbowish-part-2-stories/"/>
    <updated>2021-04-27T11:21:32-04:00</updated>
    <id>http://blog.pnkfx.org/blog/2021/04/27/road-to-turbowish-part-2-stories</id>
    <content type="html"><![CDATA[<p>It&rsquo;s story-time!</p>

<blockquote><p>As I walk, I think about a new way to walk</p></blockquote>

<p>In my <a href="/blog/2021/04/26/road-to-turbowish-part-1-goals/">previous post</a>, I described the observations that led us to select performance tooling as a focus, as well as the goals document I wrote to guide the next steps of the project. Now I want to show you the User Stories I wrote, to show what I think our customers want (and can reasonably expect) out of performance tools.</p>

<!-- more -->


<p>Everything that follows was taken verbatim<label for='&lsquo;tmbg&rsquo;' class='margin-toggle sidenote-number'></label><input type='checkbox' id='&lsquo;tmbg&rsquo;' class='margin-toggle'/><span class='sidenote'>&lsquo;Okay, </span> from the document I presented to the other members of the AWS Rust team. This document is an attempt to describe what I envisage as awesome developer experiences doing performance investigation. As with <a href="/blog/2021/04/26/road-to-turbowish-part-1-goals/">part 1</a>, I will be adding side-commentary on the right-hand margin.</p>

<blockquote><p>As I think, I&rsquo;m using up the time left to think</p></blockquote>

<p>My next post will present the design document that arose from these and other stories, as well as discussions about the realities of what we can expect to implement.</p>

<hr />

<p>Note: These are meant to be read in order: The first describes some up-front investment that the later stories either 1.) assume other developers already put in, or 2.) in the case of user “Barry”, state explicitly that such investment of effort is deliberately skipped by the developer.</p>

<blockquote><p>And this train keeps rolling off the track</p>

<p>Trying to act like something else</p>

<p>Trying to go where it&rsquo;s been uninvited</p></blockquote>

<p><label for='' class='margin-toggle'>&#8853;</label><input type='checkbox' id='' class='margin-toggle'/><span class='marginnote'>
I jumped right in and started making up a story about a newcomer to async Rust.
I did not actually look at examples of user stories as they are typically used in Agile development, or even really how it is done at AWS. It has been a long time since I had read essays describing &ldquo;how&rdquo; to do Agile development; looking at that now, I see that typical user stories are <em>one or two sentences</em>. (I&rsquo;m not sure I can properly convey what I want these tools to do in one or two sentences. I mean, it would be a place to start, but I wanted to spell out the experience. Maybe the reality is that the step I&rsquo;m doing is <em>not</em> a user story. But it <em>does</em> seem like it at least falls into the <a href="https://medium.com/the-digital-project-manager/working-backwards-a-new-version-of-amazons-press-release-approach-to-plan-customer-centric-c17991583508">&ldquo;Working Backwards&rdquo; style</a> that is promoted here at AWS. It also matches the <a href="https://rust-lang.github.io/wg-async-foundations/vision/how_to_vision/shiny_future.html">&ldquo;shiny future&rdquo; story writing</a> approach that Rust&rsquo;s Async Foundations working group has been trail-blazing (apart from the fact that I skipped the step of writing a description of the <a href="https://rust-lang.github.io/wg-async-foundations/vision/how_to_vision/status_quo.html">&ldquo;status quo&rdquo;</a> for each of the stories here).
</span></p>

<a name="User.Story.1:.Abigail"></a>
<h2>User Story 1: Abigail</h2>

<p>Abigail is getting started with async Rust development. She&rsquo;s worked her way through the Async Book and transcribed some example code. Now she&rsquo;s trying to write her first medium sized program, a terminal-based chess program, and it doesn&rsquo;t produce any output after she makes her first move and is waiting for the opponent to move.</p>

<p>After asking for advice about what to do on the Tokio Discord chat, she enables the turbowish feature in her Cargo.toml, and recompiles. She receives warnings from the compiler saying that there are calls to <code>task::spawn</code> but no contextual labels anywhere in her crate.</p>

<p>Abigail reads the compiler&rsquo;s suggestions for the kinds of declarations to add, and adds annotations accordingly, labeling her tasks. (Her program is roughly structured according to an actor model, so she has labels like &ldquo;game AI&rdquo;, &ldquo;move validator&rdquo;, and &ldquo;terminal UI&rdquo;).</p>

<p>Abigail reattempts a build, and now notices some of the previous warnings were not addressed in her change and are emited again: These warnings are about missing labels on resources, namely the channels used for communication between the tasks, e.g. &ldquo;user input&rdquo;, &ldquo;player move&rdquo;, &ldquo;opponent move&rdquo;, etc. She adds labels to the channels, and the program now compiles with no diagnostic warning. She runs her Chess program.</p>

<p>The Chess program starts up, and this time it includes, as part of its console output, a socket to connect to, which is serviced by a dedicated Turbowish thread. She runs a separate tokio-console program, connecting it to the advertised socket on the Chess program. Events begin streaming from the TurboWish thread to the <code>tokio-console</code>. The <code>tokio-console</code> output notes that it has a webserver mode available; she opts into that, and the <code>tokio-console</code> spits out a local URL to connect to. Abigail starts up a web browser and connects it to the URL. The rendered page lists the three tasks.</p>

<p>The Chess program again unexpectedly blocks (or, more precisely, livelocks) after she inputs her first move. Abigail looks at the rendered page, and notices a button that says &ldquo;task dependencies.&rdquo; She clicks it, and the page renders a picture showing a directed graph,<label for='&lsquo;directed-graph&rsquo;' class='margin-toggle sidenote-number'></label><input type='checkbox' id='&lsquo;directed-graph&rsquo;' class='margin-toggle'/><span class='sidenote'>&lsquo;This </span>
linking tasks and resources (or more generally, wakers), which depicts both 1.) what resources a task is waiting on, and 2.) what tasks are responsible for making those resources available for use.</p>

<p>The resulting rendering shows a cycle in the graph that looks like this, where circular nodes are tasks and rectangular nodes are resources shared by the tasks, like channels.</p>

<p><label for='' class='margin-toggle'>&#8853;</label><input type='checkbox' id='' class='margin-toggle'/><span class='marginnote'>
I am breaking my rule about presenting the verbatim text here. In the document I shared with my colleagues, the underlying file didn&rsquo;t support mermaid or any other markdown-oriented diagramming tools. So there I resorted to something like
<code>(terminal UI)</code> <code>-&gt;</code> <code>[board update]</code> <code>-&gt;</code> <code>(move validator)</code> <code>-&gt;</code> <code>[player move]</code> <code>-&gt;</code> <code>(terminal UI)</code>
in that document, where parentheses and square brackets represent circle vs square node shapes, differentiating tasks from resources.
But I could not bring myself to subject my readers here to that, when its so easy to put in a mermaid diagram.
</span></p>

<!-- The manual height specification is a rough guess, to allow the rest of the doc to predict the space occupied by the graph once it is rendered. -->


<div class="mermaid" style="height: 300px">
graph LR
  AI(("game AI"))
  TUI --> Update --> Validator --> Player --> TUI
  TUI(("terminal UI"))
  Update["board update"]
  Validator(("move validator"))
  Player["player move"]
</div>


<p>Notably, there are no paths in the rendered graph from [board&nbsp;move]<label for='&lsquo;board-move-typo&rsquo;' class='margin-toggle sidenote-number'></label><input type='checkbox' id='&lsquo;board-move-typo&rsquo;' class='margin-toggle'/><span class='sidenote'>&lsquo;I </span>
to (game&nbsp;AI).</p>

<p>Abigail wonders why the move validator task is waiting for a player move, when she would expect it to be waiting an opponent move from the AI.</p>

<p>She realizes there must be a error in her logic for how either the &ldquo;move&nbsp;validator&rdquo; or the &ldquo;board&nbsp;update&rdquo; are set up, since she would expect the &ldquo;game&nbsp;AI&rdquo; task to be somewhere in the path above.</p>

<p>Moving her mouse over the graph, she notices that the graph edges link to points in her source code. She starts digging in, using the provided links as direction for where to look to figure out what went wrong in her logic.</p>

<blockquote><p>And the rain falls down without my help I&rsquo;m afraid</p></blockquote>

<p><label for='' class='margin-toggle'>&#8853;</label><input type='checkbox' id='' class='margin-toggle'/><span class='marginnote'>
When I wrote these stories, I felt it would be useful for all of the characters to have names where their first letters corresponded to the letters of the Alphabet: Abigail, Barry, Chris, Daphne. Some feedback I got back almost immediately from Niko Matsakis was &ldquo;Why didn&rsquo;t you re-use the <a href="https://nikomatsakis.github.io/wg-async-foundations/vision/characters.html">characters from the Async Vision cast</a>?&rdquo; I don&rsquo;t have any great answers to that. (The obvious answer was a sheepish &ldquo;I haven&rsquo;t read the Async Vision document yet&hellip;&rdquo;; I have corrected that oversight since then.)
</span></p>

<a name="User.Story.2:.Barry"></a>
<h2>User Story 2: Barry</h2>

<p>Barry is an experienced tokio developer. He has been asked to help out with an AWS cloud service using tokio. The developers of the service are seeing higher latencies than expected for relatively small service requests.</p>

<p>Barry enables tokio&rsquo;s turbowish feature. He opts not to take the compiler&rsquo;s diagnostic suggestions regarding missing contextual labels and downgrades the diagnostic to <code>#![allow]</code> across the crate, knowing that TurboWish will infer labels and attach them automatically based upon crate and module names (and a fixed number of stack frames, when debuginfo is available).</p>

<p>Barry connects <code>tokio-console</code> to the cloud service&rsquo;s socket, and chooses its terminal user-interface instead of the webserver mode.</p>

<p>Barry first asks for a live feed of tasks transition between (<code>running</code>, <code>waiting</code>, <code>ready</code>). The feed produces too much output to the terminal, so Barry sends it to a file instead, and then inspects it in a text editor, trying to see trends by eye. It is a lot of data though, too much for Barry to interpret without more tooling.</p>

<p>Barry has dealt with parsing this output before, though.</p>

<p>Barry has a home-grown script to extract a CSV file with numeric data from the output. Barry imports the CSV file into a spreadsheet and then constructs a histogram with buckets of ranges of individual wait-times, and how many tasks’ transition points are in each bucket.</p>

<p>From this, Barry identifies a small set of tasks that spent an unusually long time in the <code>waiting</code> state. Going back to the original feed, Barry finds the the records for those long waits, which include a link to the point in the source code where the long waits occurred.</p>

<p>Barry looks, and sees a call to <code>std::thread::sleep</code> instead of tokio&rsquo;s sleep function. [TODO: I&rsquo;d be happy to put in some other
example here of blocking code that should be replaced with non-blocking code.]<label for='&lsquo;todo-other-examples&rsquo;' class='margin-toggle sidenote-number'></label><input type='checkbox' id='&lsquo;todo-other-examples&rsquo;' class='margin-toggle'/><span class='sidenote'>&lsquo;This </span></p>

<p>Barry replaces the call <code>std::thread::sleep</code> with tokio&rsquo;s sleep function, and returns to the histogram to see what other instances of unusually long wait times he can find.</p>

<blockquote><p>And my lawn gets wet though I&rsquo;ve withheld my consent</p></blockquote>

<p><label for='' class='margin-toggle'>&#8853;</label><input type='checkbox' id='' class='margin-toggle'/><span class='marginnote'>
With the Chris story, we have a sudden shift from async-oriented performance issues to compiler developer performance issues. what can I say other than <a href="https://thewritepractice.com/write-what-you-know/">&ldquo;write what you know&rdquo;</a>.
</span>
<label for='' class='margin-toggle'>&#8853;</label><input type='checkbox' id='' class='margin-toggle'/><span class='marginnote'>
(Interestingly, all the essays I can find on that <a href="https://tvtropes.org/pmwiki/pmwiki.php/Main/WriteWhatYouKnow">trope</a> indicate that it is meant to be about knowledge of <em>inner emotions</em>, not about facts or experience.)
</span></p>

<a name="User.Story.3:.Chris"></a>
<h2>User Story 3: Chris</h2>

<p>Chris is a contributor to the Rust compiler, <code>rustc</code>. Chris is well-versed with Rust, at least for batch programs like the compiler, but they do not do any async Rust development. Chris wants to gain better understanding of memory usage internal to <code>rustc</code> itself.</p>

<p>After asking around in the <code>#compiler-team</code> Zulip stream, Chris enables the <code>build.heap_inspector</code> setting in <code>rustc</code>&rsquo;s build
configuration file, and rebuilds the compiler.</p>

<p>Chris also fires up the TurboWish web frontend. This invocation of TurboWish uses a specialized config file developed and maintained by the Rust compiler team that handles interpreting the types that are special to the compiler.</p>

<p>Chris uses environment variables to indicate which points in the compiler&rsquo;s control flow are of interest to them. More specifically, Chris wants to inspect the heap as it stands immediately after the borrow-checker runs.</p>

<p>The compiler obliges: right after the borrow-checker runs, it starts from a set of known roots (tagged as such ahead of time by the rustc developer) and traverses the ownership graph from those roots,<label for='&lsquo;gc&rsquo;' class='margin-toggle sidenote-number'></label><input type='checkbox' id='&lsquo;gc&rsquo;' class='margin-toggle'/><span class='sidenote'>&lsquo;You </span> emitting a description of the arcs it encounters during its traversal. For each heap-allocated value the traversal encounters, the traversal code also
includes information needed to reconstruct its &ldquo;payload size&rdquo;; i.e., enum values will include their discriminant, vectors and string include their length, etc.</p>

<p>The TurboWish web front end receives this stream of graph traversal data. It uses this to provide a table describing the number of objects of each type, and how much internal fragmentation it detects based on the reported payload sizes. Chris inspects this table and determines that that there is an opportunity to reduce fragmentation by changing one of the enums to use a <code>Box</code>. Chris tries it out and sees the memory consumption of the compiler go down, and files a pull request
with the change.</p>

<p>(Note: This user story may or may not not provide value over other tools like dhat, depending on 1. whether it allows tracking allocations at a finer grain than malloc calls (e.g. sub-allocations within an arena) and/or 2. how much value one puts on being able to inspect portions of the heap rooted at certain owners. See also <a href="#Appendix">the appendix</a>, which includes a more ambitious “dream” proposal for Chris, but also one that I personally am not as sure actually pays off in terms of customer value versus mere “coolness” factor.)</p>

<blockquote><p>When this grey world crumbles like a cake</p></blockquote>

<a name="User.Story.4:.Daphne"></a>
<h2>User Story 4: Daphne</h2>

<p><label for='' class='margin-toggle'>&#8853;</label><input type='checkbox' id='' class='margin-toggle'/><span class='marginnote'>
With Daphne&rsquo;s story, we return to async-oriented performance analysis.
Async is a hot topic, and I figured it was worth exploring other stuff we could deliver. In this case, the idea is to turn the internal logging data into a rendered message sequence chart. (I actually do not know if people use message sequence charts on real logs in practice. I have seen them used <em>very</em> often for presenting small snippets that explain a protocol, but are they actually useful for traversing a complex series of interactions? I can imagine it could be, especially in an interactive presentation that can highlight links and automatically re-center on a selected end of a given arc in a graph.
</span>
Daphne is maintaining an existing a web service built atop tokio. She gets reports of poor performance for certain input queries that match the &ldquo;E&rdquo; command for her service, which already has TurboWish integrated. In response, she attaches <code>tokio-console</code> to her service, and tells it to trace the flow of requests matching the &ldquo;E&rdquo; command (more concretely, <code>[{req.path="/Q"}]=trace</code>), and then fires up the TurboWish web front-end.</p>

<p>Daphne chooses a tab that says &ldquo;Show Scheduler.&rdquo; The resulting page looks something like Message Sequence Chart: Each of tokio&rsquo;s executor threads has a vertical line, and as futures are polled, they have corresponding boxes on the corresponding thread. Since Daphne has limited the output to just events related to the &ldquo;E&rdquo; command, all the futures she sees being scheduled are part of that query.</p>

<p>From skimming the resulting charts, Daphne sees that when the &ldquo;E&rdquo; futures are being polled, they seem to yield again promptly. She does see some evidence the future is migrating to different threads, and she makes a note to try to investigate whether there is a way to ask tokio to avoid such thrashing (and also, whether there are metrics should could gather about whether doing so could help).</p>

<p>There are also points in the program flow when <em>no</em> future related to the &ldquo;E&rdquo; query is scheduled. The event stream does not include information about which futures are polled during those times. Those portions of the executor threads vertical lines are colored dark green: they may be doing useful work, but its not work directly related to the events that have been filtered in.</p>

<p>Daphne realizes that she needs to find out whether the &ldquo;E&rdquo; futures are being left unexecuted because they&rsquo;re still waiting for their corresponding wakers to be invoked, or if the &ldquo;E&rdquo; futures are all ready and there is some other issue in the scheduler (or in the other tasks that causes them to starve the executing threads). Daphne goes to <code>tokio-console</code> and issues the command requesting the feed of all tasks transitioning between (<code>running</code>, <code>waiting</code>, <code>ready</code>). With that, the message sequence chart now shows that her &ldquo;E&rdquo; futures are indeed ready much of the time. She also sees that there are large blocks of time where all of the threads in the pool are running without any interrupt. Daphne hovers the mouse over those rendered blocks of time,  and a pop-up window shows a description of the futures that are being polled at that time. Daphne goes off to investigate that piece of code, and discovers a <code>for</code>-loop with some semi-expensive body that never yields to the executor.</p>

<a name="Appendix"></a>
<h1>Appendix</h1>

<blockquote><p>I&rsquo;ll be hanging from the hope</p>

<p>That I&rsquo;ll never see that recipe again</p></blockquote>

<a name="User.Story.3b:.Chris.s.Dream"></a>
<h2>User Story 3b: Chris&rsquo;s Dream</h2>

<p>Chris wants to inspect the heap as it stands immediately after the borrow-checker runs.</p>

<p>The compiler obliges: right after the borrow-checker runs, it pauses and prompts for the user to connect TurboWish. Chris connects the <code>rustc-console</code> app and interactively asks what root objects are available to inspect. One of the named objects in the result is the &ldquo;MirBorrowckCtxt&rdquo; (i.e. the borrow-checking context). Still working at the terminal <code>rustc-console</code>, Chris first asks for how much memory is solely owned, potentially indirectly by the &ldquo;MirBorrowckCtxt&rdquo; object. <code>rustc-console</code> spits out a number. Chris then asks for how much memory is owned, potentially shared with others (e.g. via <code>Rc</code>), by the object. <code>rustc-console</code> spits out another, much larger number.</p>

<p>Chris connects the TurboWish web front-end, and then queries for a ownership tree describing the values owned by the &ldquo;MirBorrowckCtxt&rdquo; object.</p>

<p>TurboWish does a graph traversal over the owned heap allocated objects, starting from the borrow-checking context (<code>MirBorrowckCtxt</code>) as the root, and emits a description of the arcs it encounters during its traversal, as well as well as the data payload for any fields of types that have been previously marked by the rustc developers as of interest.</p>

<p>The TurboWish web front end renders the resulting graph. But in addition to the direct ownership relatinships implied by the Rust language semantics the graph, it also includes arcs for any <code>&amp;</code>/<code>&amp;mut</code> references in the graph, and it <em>also</em> includes some domain-specific dotted arcs for keys into tables that are meant to be interpreted as references. (This of course is only possible due to the rustc-specialized config file that was included when TurboWish was loaded up.)</p>

<p><label for='' class='margin-toggle'>&#8853;</label><input type='checkbox' id='' class='margin-toggle'/><span class='marginnote'>
I think this whole appendix was just an excuse to try to squeeze in a reference to Hyperbolic Trees. Just over twenty years ago, I spent a summer (or was it a year) hacking together code to render a graph via such trees as part of a project called <a href="http://alumni.media.mit.edu/~wex/CHI-99-Footprints.html">Footprints</a>; the linked paper still has screenshots of it.
</span></p>

<p>However, since the object graph is massive, the rendering does not fit on the window. Chris first toggles an option to change the rendering to use a hyperbolic tree (see <a href="https://en.wikipedia.org/wiki/Hyperbolic_tree">https://en.wikipedia.org/wiki/Hyperbolic_tree</a>), where the current object is presented centrally, and immediate children are surrounding smaller nodes, and grand-children are still smaller, et cetera. The hyperbolic tree presentation compacts the view significantly, at the cost of obscuring details of distant descendants and ancestors, as well as cousins.</p>

<p>There is also an option on the presentation UI to have the circles for each node be different sizes depending on how much space they individually occupy on the heap (not including their linked children); Chris enables this setting, just to get a rough visual feeling for where memory space is going in the ownership tree.</p>

<hr />

<p>And that&rsquo;s all the user stories. That&rsquo;s the whole document.</p>

<p>For the sequel, I will be presenting the design document that I think best represents the plan going forward.</p>

<p>We are still figuring things out, to some extent, but I continue to dream about what we can do for our customers, the Rust developers of the world.</p>

<blockquote><p>When the word comes down &ldquo;Never more will be around&rdquo;</p>

<p>Thought I&rsquo;ll wish we were there, I was less than we could bear</p>

<p>And I&rsquo;m not the only dust my mother raised</p>

<p>I am not the only dust my mother raised</p></blockquote>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Road to TurboWish; Part 1: Goals]]></title>
    <link href="http://blog.pnkfx.org/blog/2021/04/26/road-to-turbowish-part-1-goals/"/>
    <updated>2021-04-26T12:51:35-04:00</updated>
    <id>http://blog.pnkfx.org/blog/2021/04/26/road-to-turbowish-part-1-goals</id>
    <content type="html"><![CDATA[<p>This is a post about some recent history. I want to tell the world about a project I am leading at Amazon Web Services, called &ldquo;TurboWish.&rdquo;</p>

<p>TurboWish, in a nutshell, is our umbrella term for a planned suite of tools for understanding your Rust program&rsquo;s dynamic behavior. We want the tools to especially focus on providing insights into the <em>performance</em> characteristics of your program.</p>

<!-- more -->


<p>Let me take a moment to tell you what has happened so far: How did I get here?</p>

<p>(if you want skip the history/motivations and jump <a href="#doc:.Opening.Line">straight to the doc</a>, you can follow that link; you may find yourself
in another part of the world.)</p>

<a name="Into.the.blue.again"></a>
<h2>Into the blue again</h2>

<p>About six months ago, I left Mozilla and joined Amazon Web Services (AWS). I am now part of a new team: the AWS Rust team.</p>

<p>Our team charter is simple: &ldquo;The AWS Rust team works to make Rust performant, reliable, and productive for all its users.&rdquo;</p>

<p>Details of what that means are spelled out via <a href="https://aws.amazon.com/blogs/opensource/how-our-aws-rust-team-will-contribute-to-rusts-future-successes/">our team&rsquo;s tenets</a>.
One of those tenets, one that is incredibly important to me, is that &ldquo;we work in the open.&rdquo; This blog post is itself my own attempt to follow through on that promise: I want to be more open about what I&rsquo;ve been writing down and circulating amongst a relatively small group of people, and try to be better about putting my draft ideas out into the open from the start going forward.</p>

<a name="Same.as.it.ever.was"></a>
<h2>Same as it ever was</h2>

<p>From my perspective, I still have the same personal career goals: make the Rust programming language an awesome option for developers, by improving the code of the Rust compiler, the design of the Rust language, and the organization of the Rust community.<label for='&lsquo;not-improve-community&rsquo;' class='margin-toggle sidenote-number'></label><input type='checkbox' id='&lsquo;not-improve-community&rsquo;' class='margin-toggle'/><span class='sidenote'>&lsquo;Our </span></p>

<p>Those were my goals when I was at Mozilla, and they are still my goals now.</p>

<a name="You.may.ask.yourself"></a>
<h2>You may ask yourself</h2>

<p>What do performance tools have to do with those goals?</p>

<p>Our team&rsquo;s inspiration for this focus was based on a few observations.</p>

<p>Part of Rust&rsquo;s promise, the reason people are trying Rust out at all, is that it says it can give you the kind of high-performance that in the past was normally the realm of low-level languages like C or C++.<label for='&lsquo;or-fortran&rsquo;' class='margin-toggle sidenote-number'></label><input type='checkbox' id='&lsquo;or-fortran&rsquo;' class='margin-toggle'/><span class='sidenote'>&lsquo;Or </span></p>

<p>At a customer-obsessed company like Amazon, that promise raises an important question.
Are our team&rsquo;s customers,<label for='&lsquo;on-customer-term&rsquo;' class='margin-toggle sidenote-number'></label><input type='checkbox' id='&lsquo;on-customer-term&rsquo;' class='margin-toggle'/><span class='sidenote'>&lsquo;Some </span>
the developers using Rust, actually seeing such performance wins in practice?</p>

<a name="There.is.water.at.the.bottom.of.the.ocean"></a>
<h2>There is water at the bottom of the ocean</h2>

<p>Based on some discussions and informal interviews with fellow Rust developers, I saw three groups of people with differing answers to that question.</p>

<p>The first group says &ldquo;Rust is great! Once I got it compiling and my unit tests passing, the code works and meets my performance expectations.&rdquo; These customers always made me happy; they are usually happy to then point out what pet features they want to see in the future.</p>

<p>The second group says: &ldquo;I got it compiling, but its not actually as fast as I had hoped. <strong>What should I do now?</strong>&rdquo;</p>

<p>Okay, to be fair, I&rsquo;m making a massive over-generalization there. The second group doesn&rsquo;t always say that. Some of them do <a href="https://blog.mozilla.org/nnethercote/2019/10/11/how-to-speed-up-the-rust-compiler-some-more-in-2019/">extensive analysis</a> to identify awesome ways to make things faster. Some also document exactly what they did and <a href="http://likebike.com/posts/How_To_Write_Fast_Rust_Code.html">how you can do it too</a>.</p>

<p>But the point remains: If Rust <em>isn&rsquo;t</em> meeting your performance goals, its not always obvious what to do. Some people with a lot of in-depth experience with compilers or systems analysis have tools in their utility belt that work well for C/C++ and &hellip; they sort of work for Rust.</p>

<p>But those tools do not work as well as I would like, and I&rsquo;m not sure they are the right answer for the bulk of our community.
I said five years ago that I want Rust to be <a href="https://www.infoq.com/presentations/rust/">Systems Programming for Everybody</a>, and part of that story is that we need tools that everybody can use and understand.</p>

<a name="How.do.I.work.this."></a>
<h2>How do I work this?</h2>

<p>The third group says: &ldquo;I struggle to figure out what design to use. I struggle to get my service compiling. You are asking me what I think about performance, but  I&rsquo;m debugging deadlocks from my <code>async</code> code.&rdquo;</p>

<p>This third group raises an entirely different line of thinking when it comes to tooling. When I first starting thinking about performance monitoring tools, I was thinking solely in terms of gathering and presenting metrics, such as CPU cycles, memory utilization. But this third group represents a broad set of customers for whom such focus is premature: They are hitting road blocks that prevent their project from ever leaving the prototype phase. One big source of problems was <code>async</code> code; there&rsquo;s a good chance that <code>async</code>-specific tooling will provide the biggest return on investment here.</p>

<p>The concerns of the second and third groups what led us to the TurboWish project: tools that will help our customers make Rust deliver on its promises: <a href="https://www.rust-lang.org/">performant, reliable, productive</a>.</p>

<a name="Letting.the.days.go.by"></a>
<h2>Letting the days go by</h2>

<p>After performing a set of informal interviews with various customers both within and outside of AWS, I felt confident that there <strong>are</strong> real problems here to solve. We want Rust developers to have good tools<label for='&lsquo;lang-feats&rsquo;' class='margin-toggle'> &#8853;</label><input type='checkbox' id='&lsquo;lang-feats&rsquo;' class='margin-toggle'/><span class='marginnote'>&lsquo;Ideally, </span>
on hand that will answer their questions.</p>

<p>So, I jumped into writing a goals document, so that our team could explain to other teams at AWS, and ourselves, what we want to make. I shared it with the rest of the AWS Rust team in the middle of February 2021; they had lots of feedback, but I am not including that here (mostly to avoid having to coordinate authorship of this blog post).</p>

<p>I am ending this blog post with that goals document, warts and all, along with meta-commentary in the right-hand margin notes.
In follow-on blog posts this week, I will share some of the next steps that followed after I wrote this.</p>

<a name="doc:.Opening.Line"></a>
<h3>doc: Opening Line</h3>

<p><label for='' class='margin-toggle'>&#8853;</label><input type='checkbox' id='' class='margin-toggle'/><span class='marginnote'>
You can see in the opening line itself the focus on <code>async</code>/<code>await</code>, for better or for worse.
</span>
TurboWish is a framework for profiling Rust programs, focused on illuminating the performance and resource usage of task-oriented code written with async/await.</p>

<a name="doc:.Goals"></a>
<h3>doc: Goals</h3>

<p><label for='' class='margin-toggle'>&#8853;</label><input type='checkbox' id='' class='margin-toggle'/><span class='marginnote'>
I played a bit of a semantic shell game here, with my use of the term &ldquo;production code.&rdquo; That term could be interpreted as &ldquo;code deployed as a live service.&rdquo; Or it could be interpreted as &ldquo;code compiled in release mode, but still running on development boxes.&rdquo; I plan to talk more about this distinction in later posts, but the short version is: I think we can provide great value today to developers working on their development boxes, without trying to concern ourselves with making a tool that is sufficiently low-overhead and security risk-free that it could be part of a deployed system.
</span>
<em>Profile Production Code</em>: Incorporating the TurboWish Framework is low-overhead: it can be incorporated into production code without producing an undue maintenance burden and without incurring significant performance overhead.</p>

<p><em>Domain-specific Feedback</em>: Frameworks and applications can provide data for specialized metrics, specific to their internal architecture.</p>

<p><em>Understand Hidden Costs and Connections</em>: Frameworks like tokio ease writing asynchronous code because they hide a number of details behind abstractions (such as generator code produced by the Rust compiler, or task queues managed by the tokio runtime). TurboWish exposes those hidden details, allowing developers to correlate them with other program events. It also exposes connections that humans usually have to reconstruct by hand (such as future to resource to future chains that can yield deadlock), allowing one to directly see from Rust’s ownership model how resources are being held in the object graph.</p>

<p><em>Framework Agnostic</em>: Many of Rust’s customers use tokio, but not all of them. async-std  and fuschia_async are other frameworks for asynchronous programming. TurboWish can provide value to any such framework (though it may also provide framework-specific functionality when warranted). For our initial releases, we can focus on tokio alone, but expect integration with others if tokio proves successful.</p>

<p><label for='' class='margin-toggle'>&#8853;</label><input type='checkbox' id='' class='margin-toggle'/><span class='marginnote'>
I included this goal specifically because I had done a bunch of investigation into using <a href="https://rr-project.org/"><code>rr</code></a>, and discovered during that time that some of the cloud development machines hosted on <a href="https://aws.amazon.com/ec2/">EC2</a> do not support the performance counters that you need for <code>rr</code> to function.
</span>
<em>EC2 Instance Type Agnostic</em>: If we make use of any OS specific features (e.g. dtrace probes), they will be available on all EC2 AL2 instances, regardless of instance-type. (Specifically, we cannot require access to CPU performance counters.)</p>

<p><label for='' class='margin-toggle'>&#8853;</label><input type='checkbox' id='' class='margin-toggle'/><span class='marginnote'>
It was an interesting exercise writing this schedule. There are a number of constraints that I was trying to meet that are not represented in this table.
The biggest one was that the Rust release schedule itself follows a six-week cadence; if TurboWish needs any support from <code>rustc</code> itself, and we want it to be available in the stable version of the compiler at the end of October, then that means any such support needs to land in the nightly version of <code>rustc</code> before July 29th.
</span></p>

<a name="doc:.Milestones"></a>
<h3>doc: Milestones</h3>

<table>
<thead>
<tr>
<th>Milestone</th>
<th>Deadline</th>
</tr>
</thead>
<tbody>
<tr>
<td>3 to 5 User Stories identified for core focus</td>
<td>26 Feb 2021</td>
</tr>
<tr>
<td>Development Tracks identified</td>
<td>26 Mar 2021</td>
</tr>
<tr>
<td>PR/FAQ published</td>
<td>2 Apr 2021</td>
</tr>
<tr>
<td>3 Launch Partners established</td>
<td>30 Apr 2021</td>
</tr>
<tr>
<td>alpha prototype</td>
<td>2 Jul 2021</td>
</tr>
<tr>
<td>feedback gathered from demo of alpha to Launch Partners</td>
<td>16 Jul 2021</td>
</tr>
<tr>
<td>beta release</td>
<td>20 Aug 2021</td>
</tr>
<tr>
<td>beta integrated with Launch Partner code bases</td>
<td>17 Sep 2021</td>
</tr>
<tr>
<td>Evaluation Report of beta (interviews with Launch Partners)</td>
<td>24 Sep 2021</td>
</tr>
<tr>
<td>1.0 release</td>
<td>29 Oct 2021</td>
</tr>
</tbody>
</table>


<a name="doc:.Milestone.explanation"></a>
<h3>doc: Milestone explanation</h3>

<p><em>Development Tracks</em>: Some features of TurboWish will provide the most value to customers if they are developed in concert with additions to other components of the Rust ecosystem, such as the Rust compiler. However, we are not the sole owners of the Rust ecosystem nor those components. We need to identify target components of interest early (and I am assuming that part of that identification will require actual prototyping, which is why I am allocating a month for such prototyping in parallel with drafting the PR/FAQ<label for='&lsquo;pr-faq&rsquo;' class='margin-toggle sidenote-number'></label><input type='checkbox' id='&lsquo;pr-faq&rsquo;' class='margin-toggle'/><span class='sidenote'>&lsquo;I </span>), so that we can properly prioritize such development. In each case where we do not own the component, we must also establish the backup plan if our desired changes will not land in time for use in the product this year.</p>

<p><em>Launch Partners</em>: Customers within Amazon are willing to evaluate pre-release versions of the product. We should strategically select three such customers to partner with us; these are the Launch Partners. We will give each such launch partner 1.) demonstrations of the alpha proof of concept, 2.) access to the beta minimum viable product, and 3.) dedicated engineering time for integrating the beta into their service. In exchange, the launch partner will give us feedback on the alpha and beta versions of the product (which will inform each subsequent development sprint).</p>

<p><label for='' class='margin-toggle'>&#8853;</label><input type='checkbox' id='' class='margin-toggle'/><span class='marginnote'>
For some reason I was especially proud of the distinction being drawn in this paragraph. I have a somewhat superficial understanding of project management and Agile development methods, so I was not really thinking about whether demo&rsquo;s are common products of a sprint. (And a <a href="https://www.jrothman.com/mpd/2007/10/release-able-vs-demo-able/">post by Johanna Rothman</a> makes the great point that even a product that is &ldquo;only&rdquo; demo-able has still demonstrated <em>integration amongst the team</em>.)
From my perspective, the demo/release distinction had an entirely different motivation: I simply did not see time in the schedule for the year for two full release plus integration plus customer-feedback cycles.
</span>
<em>Alpha Demo</em> versus <em>Beta Release</em>: We want to move quickly, develop a minimum viable product and then iterate on it until we have something that delights our customers. We also want to work with a set of dedicated launch partners to evaluate an early version of the product (the beta). However, a product like this is unlikely to be a tool that can be trivially integrated: we expect there to be some amount of development effort associated with linking TurboWish into a given code base. Therefore, we do not expect our launch partners to be able to participate in multiple iterations of evaluating the product, simply due to the amount of development effort each integration is likely to take. So, we propose using different evaluation methodologies for different iteration cycles: For the alpha version, we will integrate TurboWish into code bases that we choose ourselves, give demos of the integrated result to our Launch Partners, and use their feedback in subsequent development of the alpha. For the beta version, we will work with our Launch Partners to integrate TurboWish into their code bases, and then at the end of the integration period, we will use the feedback they provide to make the final changes to the product.</p>

<a name="doc:.Risks..Mitigations"></a>
<h3>doc: Risks, Mitigations</h3>

<blockquote><p>Risk: Time from “development tracks identified” to “PR/FAQ published” is only a week.<label for='&lsquo;dev-track-to-pr-faq&rsquo;' class='margin-toggle sidenote-number'></label><input type='checkbox' id='&lsquo;dev-track-to-pr-faq&rsquo;' class='margin-toggle'/><span class='sidenote'>&lsquo;This </span></p></blockquote>

<p>Mitigation: We need to develop the PR/FAQ in parallel with doing the feasibility studies that identify the development tracks. (But I do not want to make them independent milestones; I want to be confident that the features in the PR/FAQ can be constructed before I try to enlist Launch Partners.)</p>

<blockquote><p>Risk: Rust compiler leadership/maintenance will distract pnkfelix.<label for='&lsquo;compiler-work&rsquo;' class='margin-toggle sidenote-number'></label><input type='checkbox' id='&lsquo;compiler-work&rsquo;' class='margin-toggle'/><span class='sidenote'>&lsquo;Another </span></p></blockquote>

<p>Mitigation 1. Get buy-in from others and spread development effort</p>

<p>Mitigation 2. Compiler Team focus for 2021 is rustc contributor experience, especially w.r.t. performance. Hopefully synergies will emerge from that.</p>

<blockquote><p>Risk: Not much time remaining in February to establish user stories. Felix’s personal focus for short term are memory usage issues, and so he has been contributing stories related to that. But many customers express concern related to async/await, especially about understanding why their tasks fail to progress (i.e. sources of deadlock).</p></blockquote>

<p><em>(No mitigation documented.)</em><label for='&lsquo;no-mitigation&rsquo;' class='margin-toggle sidenote-number'></label><input type='checkbox' id='&lsquo;no-mitigation&rsquo;' class='margin-toggle'/><span class='sidenote'>&lsquo;I </span></p>

<blockquote><p>Risk: Some features may depend on some amount of GC style tracing, potentially starting from local owned variables on the stack as roots, and in any case traversing values on the heap. (For example, automatically dissecting ownership chains between futures and resources in order to identify causes of deadlock could make use of such tracing.) pnkFelix has experience in this area and believes it to be a solvable problem (especially given the profiling goal, as opposed to correct integration with arbitrary 3rd party GC tech), but it is not a settled problem.</p></blockquote>

<p>Mitigation: Leverage ownership of relevant frameworks where possible. E.g. you don’t need to trace the local stack if you know your “root set” of interest is the set of tokio tasks. And you don’t need to make an general-purpose value-tracing system when a make-shift trait and associated derive will suffice for the specific problem at hand.</p>

<a name="Time.isn.t.holding.us...Time.isn.t.after.us"></a>
<h2>Time isn&rsquo;t holding us / Time isn&rsquo;t after us</h2>

<p>And that&rsquo;s the goals doc, as it stood in mid-February</p>

<p>Like I said above, there was a bit of a journey to get to this point. And even with this document in hand, we do not have enough to start making code: I wouldn&rsquo;t be able to hand this to a programmer and say &ldquo;do this.&rdquo;</p>

<p>But I had goals. And I had a schedule. What was next on the schedule? <em>User Stories.</em> (Those will be the subject of the next blog post.)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[GC and Rust Part 2: The Roots of the Problem]]></title>
    <link href="http://blog.pnkfx.org/blog/2016/01/01/gc-and-rust-part-2-roots-of-the-problem/"/>
    <updated>2016-01-01T00:00:00-05:00</updated>
    <id>http://blog.pnkfx.org/blog/2016/01/01/gc-and-rust-part-2-roots-of-the-problem</id>
    <content type="html"><![CDATA[<p>This is the second in a series of posts will discuss why garbage
collection is hard, especially for Rust, and brainstorm about
solutions to the problems we face.</p>

<p>The <a href="/blog/2015/11/10/gc-and-rust-part-1-specing-the-problem/">previous post</a> wrote down some criteria for integration.
Now I want to delve into why satisfying those criteria is hard,
at least in Rust as it stands today.</p>

<!-- more -->




<script>
// See https://github.com/imathis/octopress/issues/424
$(document).ready(function(){
    $('body').addClass('collapse-sidebar');
});
</script>


<p>(The body of this post makes heavy use of client-side rendering,
because of author idiosyncrasies.  You may need to wait a moment while
the supporting Javascript loads.)</p>

<script src="http://blog.pnkfx.org/javascripts/viz.js" charset="utf-8"></script>


<script src="http://blog.pnkfx.org/javascripts/js_to_dot.js" charset="utf-8"></script>


<script src="http://blog.pnkfx.org/javascripts/gc_rendering.js" charset="utf-8"></script>


<a name="Simplifying.Assumptions"></a>
<h2>Simplifying Assumptions</h2>

<p>Let us make some assumptions, so that we can focus on why
this problem is still hard even <em>after</em> being somewhat simplified.</p>

<p>As previously discussed in <a href="http://blog.pnkfx.org/blog/2015/10/27/gc-and-rust-part-0-how-does-gc-work/#how-gc-works">the proloque</a>, one can think of the
main program and the GC as <em>coroutines</em>. We will continue with that
mind set.</p>

<p>Let us assume (for now) that the main program will not be running
concurrently with the GC;<label for='&lsquo;no-concurrent-mutation&rsquo;' class='margin-toggle sidenote-number'></label><input type='checkbox' id='&lsquo;no-concurrent-mutation&rsquo;' class='margin-toggle'/><span class='sidenote'>&lsquo;This </span> or more specifically, the main program
thread(s) will not read or write any GC roots nor GC Heap-allocated
objects concurrently with the GC thread.</p>

<p>In addition, let us assume that in the context of the GC coroutine, no
mutator roots are live values in CPU registers;<label for='&lsquo;no-register-roots&rsquo;' class='margin-toggle sidenote-number'></label><input type='checkbox' id='&lsquo;no-register-roots&rsquo;' class='margin-toggle'/><span class='sidenote'>&lsquo;This </span>
 in other words, all mutator register values that the GC might care about
will have been saved somewhere in a mutator stack frame
(and will be reloaded from those saved stack slots
before subsequent use by the mutator).</p>

<p>Again, these assumptions are <em>not</em> meant to be interpreted as specific
requirements of Rust&rsquo;s final solution for GC; instead, they describe a
simplified version of &ldquo;the GC integration problem&rdquo; that
I claim is <em>still</em> hard to solve for Rust in general.</p>

<p>Throughout most of this post, I will be discussing various data
structures to support GC activity. When providing concrete examples of
the runtime state, the goal will usually be to represent something analogous
to the following
fragment of an object graph (or some small variant thereof).</p>

<p id="running_example_graph"></p>




<script>
var stack = { id: "cluster_stack", label: "Stack", is_subgraph: true };
var rust_heap = { rankdir:"LR", id: "cluster_rust_heap", label: "Rust Heap", is_subgraph: true };
var gc_heap = { id: "cluster_gc_heap", label: "GC Heap", is_subgraph: true, style: "rounded" };

var o = object_record("O: StructZ", "<f0> field z (root)");
o.id = "O";
var x = object_record("X1", "...");
var y = object_record("Y", "...");
var x2 = object_record("X2", "...");
x.style = "rounded";
y.style = "rounded";
x2.style = "rounded";

var local_x = { id: "local_x", label: "local x: Gc&lt;X&gt; (root)", shape: "record" };
var local_y = object_record("StructY", "<f0> field y (root)");
var local_o = { id: "local_o", label: "local o = Box(O)", shape: "record" };

stack[1] = local_x;
stack[2] = local_y;
stack[3] = local_o;
local_x.ref = edge_from_to_ports(":e", ":id:nw", x);
local_y.ref = edge_from_to_ports(":f0", ":id", y);
local_o.box = edge_to_port(":id", o);

o.f0 = edge_from_to_ports(":f0", ":id:w", x);
rust_heap[0] = o;

gc_heap[2] = x;
gc_heap[3] = y;
gc_heap[4] = x2;

var objects = [stack, gc_heap, rust_heap];

stack.rank = "same";

post_objects("running_example_graph", objects, { rankdir:"LR", nodesep:0.2, no_dims: true, with_code: false });
</script>


<p>Instances of structured data are
shown with a label<label for='&lsquo;labels-for-presentation&rsquo;' class='margin-toggle sidenote-number'></label><input type='checkbox' id='&lsquo;labels-for-presentation&rsquo;' class='margin-toggle'/><span class='sidenote'>&lsquo;These </span>
(<code>StructY</code>, <code>O: StructZ</code>, <code>X</code>, <code>Y</code>) that identifies the data and usually includes its type.</p>

<p>Often I will omit the type of a local variable or member (such as with
<code>o</code>, <code>y</code>, and <code>z</code> above). If I want to specify the type, I will do so via
type-ascription
syntax (e.g. <code>x: Gc&lt;X&gt;</code> above), and if I want to specify the particular
value given to a variable, I will use assignment syntax (e.g. <code>o = Box(O)</code> above).
(Note that the assigned value should always be redundant, since there
should also be an arrow linking to the assigned value in these diagrams.)</p>

<p>Values of type <code>Gc&lt;T&gt;</code> hold references to objects allocated on the GC Heap.
Every object on the GC Heap will have a label that is derived from the
type <code>T</code> and, if necessary, a numeric suffix to disambiguate between
multiple instances of <code>T</code> on the GC Heap.</p>

<p>I have denoted the <em>contents</em> of the objects on the GC Heap by
ellipses, because I am focusing in this post
solely on problems related to finding the roots;
the contents of the objects referenced by the roots, and the remaining
transitively reachable objects beyond them, are not important to us today.</p>

<p>Objects allocated on the Rust Heap will tend to be boxes owned by
values of type <code>Box&lt;T&gt;</code>; they will have an identifying label and the
type of the contents (e.g. <code>O: StructZ</code> above).</p>

<p>I will tend to present examples of structured data with trivial
structs that have one field; e.g. <code>StructY</code> has a single field <code>y</code>,
and likewise <code>StructZ</code> has just the field <code>z</code>. (Of course in real
programs there will be structs and arrays with multiple members, but single field
structs simplifies the diagrams here.)</p>

<a name="Rust.complicates.Root.Identification"></a>
<h2>Rust complicates Root Identification</h2>

<p>At some point, probably in response to a memory allocation request,
the GC is going to initiate a collection.</p>

<p>That requires traversing the root set of the main program, since those
roots will be the kernel that the GC uses to identify the reachable
objects.</p>

<p>What are the options for traversing the root-set?</p>

<a name="Do.we.need.to.solve.this.problem."></a>
<h3>Do we need to solve this problem?</h3>

<p>One approach is to &ldquo;define away the problem&rdquo;; one version of this I
<a href="#Interoperation.with.a..black.box..GC">previously described</a> is to
hide the root-set itself inside the black-box abstraction
that we are interoperating with, and expose only handles that
point to the roots.</p>

<p id="target_anchor_black_box_gc_1" class="fullwidth"></p>


<p>The key principle in this picture is that the GC is meant to be
completely isolated from the state of the main program; when it does a
collection, the GC just starts from the root-set hidden within the
<code>handles</code> in the GC-heap. It does not inspect any state in the boxes
labelled &ldquo;Stack&rdquo; nor &ldquo;Rust Heap.&rdquo;</p>

<p>But a big problem with this, that I failed to stress in my earlier
post, is that you now need to <em>manage</em> the hidden-root set stored in
the <code>handles</code> array.</p>

<p>In particular, in the above picture, every entry in <code>handles</code> maps to
exactly one <code>Handle</code> value on the &ldquo;Stack&rdquo; or &ldquo;Rust Heap.&rdquo; This leads
to some troubling questions.</p>

<ul>
<li><p>What happens when you clone the box referenced by the local variable <code>o</code>: does that need to create a new entry in the hidden <code>handles</code> array?</p></li>
<li><p>How about if you instead dropped <code>o</code> &ndash; does that clear the <code>handles</code> entry at index 2?</p>

<ul>
<li><p>If not, when/how will the root set be updated appropriately?</p></li>
<li><p>If so, are previously cleared entries reused? If so, how do you determine whether an entry is available for reuse &ndash; do you keep a mark-bit on each handle?</p></li>
</ul>
</li>
<li><p>This handle array maintenance sounds expensive, maybe
we should instead periodically scan the stack to look for pointers to handles &hellip;</p></li>
</ul>


<p><label for='' class='margin-toggle'>&#8853;</label><input type='checkbox' id='' class='margin-toggle'/><span class='marginnote'>
Just to be clear: the joke here is that we are basically
suggesting layering our own semi-automated memory management system
on top of a third-party automated memory management system. We should be striving to
<em>reduce</em> our problems to smaller subproblems, not <em>reproducing</em> them.
</span>
&hellip; maybe we should rethink our overall approach here.</p>

<script>
var stack = { id: "cluster_stack", label: "Stack", is_subgraph: true };
var rust_heap = { rankdir:"LR", id: "cluster_rust_heap", label: "Rust Heap", is_subgraph: true };
var gc_heap = { id: "cluster_gc_heap", label: "GC Heap", is_subgraph: true, style: "rounded" };
var handles = object_record("handles", "<h2> Y | <h1> X | <h3> X");

var c = object_record("C", "<f0> Gc(X) | <f1> Box(O)");
c.style = "rounded";
var o = object_record("O: StructZ", "<f0> field z = Handle(2)");
o.id = "O";
var x = object_record("X", "...");
var y = object_record("Y", "...");
x.style = "rounded";
y.style = "rounded";
var local_x = { id: "local_x", label: "local x = Handle(1)", shape: "record" };
var local_y = { id: "local_y", label: "StructY | <f0> field y = Handle(0)", shape: "record" };
var local_o = { id: "local_o", label: "local o = Box(O)", shape: "record" };

o.f0 = edge_from_to_ports(":f0", ":h3", handles);

c.f0 = edge_from_to_ports(":f0", ":id", x);
c.f1 = edge_from_to_ports(":f1", ":id", o);

stack[1] = local_x;
stack[2] = local_y;
stack[3] = local_o;

rust_heap[0] = o;
gc_heap[0] = handles;
handles.x1 = edge_from_to_ports(":h1", ":id", x);
handles.y2 = edge_from_to_ports(":h2", ":id", y);
handles.x3 = edge_from_to_ports(":h3", ":id:sw", x);
local_x.handle = edge_to_port(":h1", handles);
local_y.handle = edge_from_to_ports(":f0", ":h2", handles);
local_o.box = edge_to_port(":id", o);
gc_heap[2] = x;
gc_heap[3] = y;

var objects = [stack, gc_heap, rust_heap];
post_objects("target_anchor_black_box_gc_1", objects, { rankdir:"LR", nodesep:0.2, no_dims: true });
</script>


<a name="Scanning.the.Mutator.State"></a>
<h3>Scanning the Mutator State</h3>

<p>So let&rsquo;s assume we are <em>not</em> dealing with a complete black box;
instead, the main program (aka &ldquo;the mutator&rdquo;) and the GC are going
to collaborate in some more fundamental way.</p>

<p>In other words, let&rsquo;s assume that roots are allowed to leak outside of
the GC Heap and into the mutator; no more black-box.</p>

<p>Once we have roots floating around under the control of the mutator,
we need to talk about identifying those roots by inspecting/querying the mutator
state.</p>

<p>Some relevant issues to consider on this topic:</p>

<ul>
<li><p>Are all roots <em>precisely</em> identified as roots?</p></li>
<li><p>Where can the roots reside in the mutator? (Frames on the stack? Boxes on the Rust Heap?)</p></li>
<li><p>How is the GC informed about the location of the roots in the mutator?</p></li>
<li><p>How does the mutator itself access the roots?</p></li>
<li><p>What information might the mutator maintain on the behalf of the GC?</p></li>
<li><p>Might a given root&rsquo;s value (i.e. the address of the referenced
object on the GC Heap) be changed by the GC during the collection
(in other words, does the GC rule out <a href="http://blog.pnkfx.org/blog/2015/10/27/gc-and-rust-part-0-how-does-gc-work/#pinning-support">pinning</a>)?</p></li>
</ul>


<p>Let&rsquo;s explore some of the problems associated with these
questions, especially how it relates to Rust.</p>

<a name="Are.roots.precisely.identified."></a>
<h2>Are roots precisely identified?</h2>

<p>The roots are somewhere in mutator-managed memory.
The GC will need to know the values held in those roots,
and possibly will need to update those values if the referenced
objects are moved in memory.</p>

<p>There are two basic options for root scanning: conservative or precise.</p>

<p>A <em>conservative</em> scan is needed when some of the values
might hold an actual root, but might also hold a false-positive.</p>

<p>This arises when, for example, there is not enough type information
available<label for='&lsquo;avail-types&rsquo;' class='margin-toggle sidenote-number'></label><input type='checkbox' id='&lsquo;avail-types&rsquo;' class='margin-toggle'/><span class='sidenote'>&lsquo;&ldquo;Not </span>
to know that a scanned word is meant to be interpreted by the mutator as an object
reference.</p>

<p>If there are any conservatively-scanned roots, the GC needs to
validate their values (e.g. by checking if it lies within one of the
ranges of addresses used for the objects allocated on the GC Heap),
and trace any object potentially referenced by such values.</p>

<p>An earlier discussion on &ldquo;<a href="http://blog.pnkfx.org/blog/2015/10/27/gc-and-rust-part-0-how-does-gc-work/#pinning-support">pinning</a>&rdquo; established that any object
referenced by a conservatively scanned root
cannot be moved by the GC.
Therefore, integrating with a GC that does not support object pinning
(such as a fully-copying collector)
will require we scan the roots precisely, not conservatively.</p>

<p><label for='' class='margin-toggle'>&#8853;</label><input type='checkbox' id='' class='margin-toggle'/><span class='marginnote'>
One problem with ensuring that a word on the stack is precisely identified
is that it requires close cooperation with the compiler backend.
E.g. if the backend (LLVM in the case of <code>rustc</code>) is permitted to reuse a stack
slot for two values of different types (and disjoint extents) then
we need to take care that the GC knows whether the current value in that slot
is or is not a GC reference.
(LLVM is a very expressive backend, so it provides mechanisms to account for this scenario, but it is not automatic.)
</span>
A given word in memory can be <em>precisely</em> scanned
if we ensure that the root&rsquo;s location in memory is
unambiguously interpreted by the mutator as an object reference.
I will say that such a root can be
&ldquo;unambiguously classified&rdquo; only if such assurance is established.</p>

<p>Often the ability to classify a root unambiguously is derived from
static types, runtime type information, and global system invariants.</p>

<p>Where the roots might reside influences the design space for
unambiguous classification quite a bit.
For example, if all roots are members of heap-allocated objects, then
the allocator might embed a type-tag in the header of such an object,
or segregate objects into disjoint regions of memory based on that
type.</p>

<p>Therefore, we will explore the question of where roots reside next.</p>

<a name="Where.are.the.roots."></a>
<h2>Where are the roots?</h2>

<p>There are two components to the question &ldquo;where are the roots?&rdquo;:</p>

<ul>
<li><p>Where can roots <em>possibly</em> reside?</p></li>
<li><p>Where do the roots <em>actually</em> reside?</p></li>
</ul>


<p>The first bullet is a question about the system as a whole; it is a
question that we must answer as designers.</p>

<p>The second bullet is about encoding how the GC will look up the memory
addresses of the roots (potentially with the mutator&rsquo;s help) every
time it wants to initiate a root scan.</p>

<p>The two parts interact with each other, so we will address them both
somewhat simultaneously.</p>

<p><label for='' class='margin-toggle'>&#8853;</label><input type='checkbox' id='' class='margin-toggle'/><span class='marginnote'>
This list is leaving out some other options,
such as <em>completely unconstrained</em>, where roots might live in memory
unknown to the both the GC and Rust runtime (I do not see a way this first option could work without
requiring programmers to instrument foreign code with calls to root registration
and deregistration functions),
or keeping the roots solely on a <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.5570">shadow stack</a>
with structure isomorphic to the actual stack, but not vulnerable
to disruption due to compiler code transformations (I am omitting
this second option since it is known to carry a significant performance penalty).
</span></p>

<p>Consider these options for locations where roots can reside:</p>

<ol>
<li><p><em>Constrained To Boxed Values</em>:
 Solely found embedded in boxed values on the Rust Heap.</p></li>
<li><p><em>Constrained To Stack</em>:
 Stored solely on the program stack, and</p></li>
<li><p><em>Rust-Managed But Otherwise Unconstrained</em>:
 Stored either on the stack or embedded in boxed values on Rust Heap.</p></li>
</ol>


<a name="Roots.Constrained.To.Boxed.Values..Option.1."></a>
<h3>Roots Constrained To Boxed Values (Option 1)</h3>

<p>If roots are <em>solely</em> stored in members of boxed values, then we might
store runtime-type metadata in an allocator-injected header.</p>

<p>This option is seductive: Adding a header via the runtime system&rsquo;s
<code>#[allocator]</code> crate could sidestep a significant amount of compiler
integration (maybe even all of it).</p>

<p>There are some interesting ideas to explore from that starting point,
such as collecting all such boxed values together in a linked list
whose head is known to the GC (and thus the answer to &ldquo;how does the
GC scan the roots?&rdquo; is just &ldquo;it walks the list&rdquo;<label for='&lsquo;list-maintenance&rsquo;' class='margin-toggle sidenote-number'></label><input type='checkbox' id='&lsquo;list-maintenance&rsquo;' class='margin-toggle'/><span class='sidenote'>&lsquo;Do </span>).</p>

<p>However,
constraining roots to solely live in members of boxed
values may not be feasible in Rust as it stands today.
For example, one is always free to move the instance of <code>T</code> out of a
<code>Box&lt;T&gt;</code>, deallocating the backing storage but moving the <code>T</code> into
another location, such as a stack-allocated local variable.</p>

<p>Let&rsquo;s look at the remaining two
approaches.</p>

<a name="Roots.Constrained.To.Stack..Option.2."></a>
<h3>Roots Constrained To Stack (Option 2)</h3>

<p>If roots can be stored directly on the stack (i.e. options 2 or 3 above),
then when the GC initiates a root scan, it will need to find those
roots.</p>

<p>This search of the stack can be guided by
&ldquo;stack maps&rdquo;:<label for='&lsquo;stack' class='margin-toggle sidenote-number'></label><input type='checkbox' id='&lsquo;stack' class='margin-toggle'/><span class='sidenote'>maps&rsquo; </span>
compiler-generated metadata providing a mapping from a
code address<label for='&lsquo;code-address&rsquo;' class='margin-toggle sidenote-number'></label><input type='checkbox' id='&lsquo;code-address&rsquo;' class='margin-toggle'/><span class='sidenote'>&lsquo;This </span>
to the set of stack slots<label for='&lsquo;stack-map-slot&rsquo;' class='margin-toggle sidenote-number'></label><input type='checkbox' id='&lsquo;stack-map-slot&rsquo;' class='margin-toggle'/><span class='sidenote'>&lsquo;More </span>
that hold values of interest.</p>

<p>However, restricting the roots to live solely on the stack may be
problematic for much the same reason that plagues the earlier idea of
restricting roots to boxed values: in Rust today, one is always free
to move instances of <code>T</code> from a stack-local slot into a member of a
boxed value.</p>

<p>In some circumstances, we might be able to counteract these
&ldquo;freedom of movement&rdquo; issues in a backwards-compatible manner with a compiler
plugin (lint) that analyzes the source and trys to flag any code might move a root
into an illegal location. (<a href="https://servo.org/">Servo</a> already uses <a href="https://blog.mozilla.org/research/2014/08/26/javascript-servos-only-garbage-collector/#custom-static-analysis">a lint like this</a>
for its integration with the Spidermonkey GC.)</p>

<p>Or, if we are willing to extend the language itself,
we might add marker trait <code>Immobile</code> that indicates
that values of such type <em>cannot</em> be
moved.<label for='&lsquo;hunh-moved&rsquo;' class='margin-toggle sidenote-number'></label><input type='checkbox' id='&lsquo;hunh-moved&rsquo;' class='margin-toggle'/><span class='sidenote'>&lsquo;Proper </span></p>

<p>But either of those options are just ways of enforcing a restriction,
and it will outlaw certain kinds of program composition.<label for='&lsquo;vec-composition&rsquo;' class='margin-toggle sidenote-number'></label><input type='checkbox' id='&lsquo;vec-composition&rsquo;' class='margin-toggle'/><span class='sidenote'>&lsquo;An </span></p>

<p>In practice, we simply may be better off lifting such restrictions
entirely. So, let us now consider our remaining option:
allowing roots to be embedded in values on the stack or boxed on the Rust Heap.</p>

<a name="Roots.are.Rust-Managed..But.Otherwise.Unconstrained..Option.3."></a>
<h2>Roots are Rust-Managed, But Otherwise Unconstrained (Option 3)</h2>

<p>Now we come to what is probably the most realistic option for Rust/GC integration:
allowing roots to reside anywhere that the Rust compiler or runtime knows about.</p>

<p>Arguably, I might well have <em>started</em> this discussion with this
approach, since it is by definition the most general of the three, and
thus if we <em>do</em> have a solution for it, then why not jump to it?</p>

<p>The reason I left it for last is that I suspect any design we adopt
for GC integration in Rust 1.x is going to require a hybrid of the
approaches described in the prior two sections (allocator-injected
metadata <em>and</em> stack maps), and therefore I wanted to outline them in
isolation, before I started mixing them together.</p>

<a name="GC:..Where.are.the.roots....Mutator:......"></a>
<h2>GC: &ldquo;Where are the roots?&rdquo;, Mutator: &ldquo;&hellip;&rdquo;</h2>

<p>If we assume that roots can be embedded in values either on the stack
or in boxes on the Rust Heap, then how will the GC find the roots when
it needs to scan them?</p>

<p>The support for the GC&rsquo;s root scanning capability can be seen as having three parts:</p>

<ol>
<li><p>What work does the GC itself do, on the fly, to determine the roots
when it needs them,</p></li>
<li><p>What work does the mutator do (if any) as it executes the
program<label for='&lsquo;mutator-work&rsquo;' class='margin-toggle sidenote-number'></label><input type='checkbox' id='&lsquo;mutator-work&rsquo;' class='margin-toggle'/><span class='sidenote'>&lsquo;&ldquo;Mutator </span>
to support a potential root scan by the GC in a future, and,</p></li>
<li><p>What meta-data must be gathered and emitted by the compiler
to support root-scanning?</p></li>
</ol>


<p>One idea for enabling easy GC root traversal was mentioned earlier:
why not collect the roots together in a linked list structure?
Towards this goal, we might
consider maintaining an intrusive
 links forming a list of all roots.</p>

<p id="intrusive_list_of_roots"></p>




<script>
var stack = { id: "cluster_stack", label: "Stack", is_subgraph: true };
var rust_heap = { rankdir:"LR", id: "cluster_rust_heap", label: "Rust Heap", is_subgraph: true };
var gc_heap = { id: "cluster_gc_heap", label: "GC Heap", is_subgraph: true, style: "rounded" };

var o = object_record("O: StructZ", "<f0> field z (root) | <next> next_root = null");
o.id = "O";
var x = object_record("X", "...");
var y = object_record("Y", "...");
x.style = "rounded";
y.style = "rounded";

var local_x = object_record("local_x", "<f0> (root) | <next> next_root");
var local_y = object_record("StructY", "<f0> field y (root) | <next> next_root");
var local_o = { id: "local_o", label: "local o = Box(O)", shape: "record" };

stack[1] = local_x;
stack[2] = local_y;
stack[3] = local_o;

local_x.ref = edge_from_to_ports(":f0", ":id", x);
local_y.ref = edge_from_to_ports(":f0", ":id", y);
local_o.box = edge_to_port(":id", o);

o.f0 = edge_from_to_ports(":f0", ":id:sw", x);
rust_heap[0] = o;

gc_heap[2] = x;
gc_heap[3] = y;

root_head = object_record("roots", "<next> next_root");
var anonymous_xy = {id: "anonymous_xy", style:"invis", shape: "point"};

// gc_heap[0] = root_head;

root_head.next = edge_from_to_ports(":next", ":f0", local_x);
local_x.next = edge_from_to_ports(":next", ":f0", anonymous_xy);
local_x.next.arrowhead = "none";

anonymous_xy.ref = edge_to_port(":f0:w", local_y);
local_y.next = edge_from_to_ports(":next", ":f0", o);

// anonymous_yx.ref.constraint = "false";
// anonymous_yx.ref.arrowhead = "none";

stack.rank = "same";

// root_head.presentation = invisible_edge(anonymous_yx);
// local_y.presentation = invisible_edge(local_x);
// local_x.presentation = invisible_edge(anonymous_xy);
// stack[4] = anonymous_yx;

var objects = [stack, gc_heap, rust_heap, root_head];
post_objects("intrusive_list_of_roots", objects, { rankdir:"LR", nodesep:0.2, no_dims: true, with_code: false });
</script>


<p>This is an <em>intrusive</em> list because the pointers in the list are
pointing into the interiors of objects. This allows traversing the
list to be completely uniform (from the viewpoint of the GC,
it looks like nothing more than a linked list of pairs).
In this scenario, the GC does essentially <em>zero</em> work on-the-fly
to find the locations of the roots;
maintaining the list would become the reponsibility of the mutator as
it creates and moves values with embedded roots.</p>

<p>However, Rust today does not have good support for intrusive data structures (<a href="https://github.com/rust-lang/rfcs/issues/417">RFC Issue 417</a>).
The already-mentioned capability to move values freely, as well as the
capability to swap a pre-existing <code>T</code> with the value held beind a
<code>&amp;mut T</code> reference, are among the reasons that intrusive structures
are difficult today, since it changes the addresses associated
with objects, and thus requires updating of the interior links.</p>

<p>So, what other options do we have?</p>

<p>Having the GC traverse the memory of the call-stack, even with the assistance of a stack map
to provide precise type information, will not give us the locations of all the roots,
since some are located on the Rust Heap. A stack map cannot hold the addresses of the blocks
of memory dynamically allocated for a box on the heap.</p>

<p>However, the stack map <em>can</em> hold the type information for the local
variables, and that sounds promising: If we record that a local
variable <code>o</code> has type <code>Box&lt;Struct&gt;</code>, then treat the contents of the
box on the heap as owned by the stack, so that when we encounter <code>o</code>
during the stack scan, we can recursively scan the memory of the box,
using the type <code>Struct</code> to inform the scan about how to treat each of
the embedded members.</p>

<p><label for='' class='margin-toggle'>&#8853;</label><input type='checkbox' id='' class='margin-toggle'/><span class='marginnote'>
I have slightly modified the running example to show two instances
of the local <code>x</code> on the call-stack in separate frames, each corresponding
to a distinct (recursive) invocation of the function <code>fn f</code>.
<br></br>
This is just to bring home the point that the stack map info encodes
static information about the frame for a function (at a particular call-site),
and thus recursive invocations of the same function can potentially
reuse the same entry in the stack map.
</span></p>

<p id="stack_map_boxes"></p>




<script>
var stack = { id: "cluster_stack", label: "Stack", is_subgraph: true };
var rust_heap = { rankdir:"LR", id: "cluster_rust_heap", label: "Rust Heap", is_subgraph: true };
var gc_heap = { id: "cluster_gc_heap", label: "GC Heap", is_subgraph: true, style: "rounded" };

var frame0 = { id: "cluster_frame0", label: "frame0: fn f()", is_subgraph: true };
var frame1 = { id: "cluster_frame1", label: "frame1: fn g()", is_subgraph: true };
var frame2 = { id: "cluster_frame2", label: "frame2: fn h()", is_subgraph: true };
var frame3 = { id: "cluster_frame3", label: "frame3: fn f()", is_subgraph: true };

var o = object_record("O: StructZ", "<f0> field z (root) = Gc(X1)");
o.id = "O";
var x  = object_record("X1", "...");
var x2 = object_record("X2", "...");
var y = object_record("Y", "...");
x.style = "rounded";
x2.style = "rounded";
y.style = "rounded";

var local_x = { id: "local_x1", label: "local x (root) = Gc(X1)", shape: "record" };
var local_x2 = { id: "local_x2", label: "local x (root) = Gc(X2)", shape: "record" };

var local_y = object_record("StructY", "<f0> field y (root) = Gc(Y)");
var local_o = { id: "local_o", label: "local o = Box(O)", shape: "record" };

frame0[0] = local_x;
frame1[0] = local_y;
frame2[0] = local_o;
frame3[0] = local_x2;

// frame3[0].ref = { is_edge: true, target: frame2[0], ltail: frame3.id, lhead: frame2.id, constraint: false };
// frame2[0].ref = { is_edge: true, target: frame1[0], ltail: frame2.id, lhead: frame1.id, constraint: false };
// frame1[0].ref = { is_edge: true, target: frame0[0], ltail: frame1.id, lhead: frame0.id, constraint: false };

stack[0] = frame0;
stack[1] = frame1;
stack[2] = frame2;
stack[3] = frame3;

local_x.ref = edge_to_port(":id:nw", x);
local_x2.ref = edge_to_port(":id:sw", x2);
local_y.ref = edge_from_to_ports(":f0", ":id", y);
local_o.box = edge_to_port(":id", o);

o.f0 = edge_from_to_ports(":f0", ":id:w", x);
rust_heap[0] = o;

gc_heap[2] = x;
gc_heap[3] = y;
gc_heap[4] = x2;

var objects = [stack, gc_heap, rust_heap];

stack.rank = "same";

post_objects("stack_map_boxes", objects, { rankdir:"LR", nodesep:0.2, compound: true, no_dims: true, with_code: false });
</script>


<p>The principle is that when control shifts to the GC coroutine,
it walks through the stack backtrace, consulting the stack
map for each callsite.</p>

<pre><code>stack_map_info for callsite 0x0010_ABBA in fn f:
  local x:
    offset: [...]
    type: Gc&lt;X&gt;

stack_map_info for callsite 0x0020_BACA in fn g:
  local _:
    offset: [...]
    type: StructY

stack_map_info for callsite 0x0030_C0C0 in fn h:
  local o:
    offset: [...]
    type: Box&lt;StructZ&gt;
</code></pre>

<p>From the stack map, it finds the offsets of relevant local variables
within that stack frame, and the type information for those locals, so
that it knows when it needs to dereference an pointer to inspect a
block on the Rust Heap (such as the <code>Box(O)</code> in our running example).</p>

<p>The GC will need separate meta-data describing the layout of each
type, with the offset and type of each field of interest:</p>

<pre><code>type_map_info for type StructY:
  field y:
    offset: [...]
    type: Gc&lt;Y&gt;

type_map_info for type Box&lt;StructZ&gt;:
  field 0:
    offset: [...]
    type: StructZ

type_map_info for type StructZ:
  field z:
    offset: [...]
    type: Gc&lt;X&gt;
</code></pre>

<p>The boxed objects may themselves own other root-holding objects on the Rust Heap,
like so:</p>

<p id="nested_stack_map_boxes" class="fullwidth"></p>




<script>
var stack = { id: "cluster_stack", label: "Stack", is_subgraph: true };
var rust_heap = { rankdir:"LR", id: "cluster_rust_heap", label: "Rust Heap", is_subgraph: true };
var gc_heap = { id: "cluster_gc_heap", label: "GC Heap", is_subgraph: true, style: "rounded" };

var frame0 = { id: "cluster_frame0", label: "frame0: fn f()", is_subgraph: true };
var frame1 = { id: "cluster_frame1", label: "frame1: fn g()", is_subgraph: true };
var frame2 = { id: "cluster_frame2", label: "frame2: fn h()", is_subgraph: true };
var frame3 = { id: "cluster_frame3", label: "frame3: fn f()", is_subgraph: true };

var o = object_record("O: StructB", "<f0> field b (root) = Box(Z)");
o.id = "O";
var b = object_record("Z: StructZ", "<f0> field z (root) = Gc(X1)");
b.id = "B";
var x  = object_record("X1", "...");
var x2 = object_record("X2", "...");
var y = object_record("Y", "...");
x.style = "rounded";
x2.style = "rounded";
y.style = "rounded";

var local_x = { id: "local_x1", label: "local x (root) = Gc(X1)", shape: "record" };
var local_x2 = { id: "local_x2", label: "local x (root) = Gc(X2)", shape: "record" };

var local_y = object_record("StructY", "<f0> field y (root) = Gc(Y)");
var local_o = { id: "local_o", label: "local o = Box(O)", shape: "record" };

frame0[0] = local_x;
frame1[0] = local_y;
frame2[0] = local_o;
frame3[0] = local_x2;

// frame3[0].ref = { is_edge: true, target: frame2[0], ltail: frame3.id, lhead: frame2.id, constraint: false };
// frame2[0].ref = { is_edge: true, target: frame1[0], ltail: frame2.id, lhead: frame1.id, constraint: false };
// frame1[0].ref = { is_edge: true, target: frame0[0], ltail: frame1.id, lhead: frame0.id, constraint: false };

stack[0] = frame0;
stack[1] = frame1;
stack[2] = frame2;
stack[3] = frame3;

local_x.ref = edge_to_port(":id:w", x);
local_x2.ref = edge_to_port(":id:sw", x2);
local_y.ref = edge_from_to_ports(":f0", ":id", y);
local_o.box = edge_to_port(":id", o);

o.f0 = edge_from_to_ports(":f0", ":id:w", b);
b.f0 = edge_from_to_ports(":f0", ":id:nw", x);
rust_heap[0] = o;
rust_heap[1] = b;

gc_heap[2] = x;
gc_heap[3] = y;
gc_heap[4] = x2;

var objects = [stack, gc_heap, rust_heap];

stack.rank = "same";

post_objects("nested_stack_map_boxes", objects, { rankdir:"LR", nodesep:0.2, compound: true, no_dims: true, with_code: false });
</script>


<p>To find all the roots starting from the stack
in the presence of such ownership chains
(which may go through other types like <code>Vec</code>),
the GC will need to recursively traverse the boxes,
or otherwise enqueue them onto a worklist structure.
In principle, if we can prove that certain types never
transitively own roots, then the GC should be able to skip traversing
boxed data for such types.</p>

<p>Using the stack map and type map data to find all roots transitively
owned by the stack is a promising approach. What is the catch, if any?</p>

<a name="Unsafe.Pointers"></a>
<h2>Unsafe Pointers</h2>

<p><label for='' class='margin-toggle'>&#8853;</label><input type='checkbox' id='' class='margin-toggle'/><span class='marginnote'>
The <code>from_raw</code> method that converts a <code>*mut T</code> to <code>Box&lt;T&gt;</code>
is unsafe, but <code>into_raw</code> is a safe method. Safe code
can always convert a <code>Box&lt;T&gt;</code> to a <code>*mut T</code>, and clients
expect it to also be reasonable to round-trip via <code>from_raw</code>.
</span>
What should we do about unsafe pointers <code>*mut T</code> and <code>*const T</code>.
For example, it is not uncommon for library code to convert
boxed data <code>Box&lt;T&gt;</code> to a <code>*mut T</code> or vice versa;
that is an ownership transfer.</p>

<p>I used <code>local o = Box(O)</code> above (where <code>o: Box&lt;StructB&gt;</code>),
but it is entirely possible that <code>o</code> has type <code>*mut StructB</code>.</p>

<p>Here are some options for how to handle unsafe pointers:</p>

<ul>
<li><p>Skip unsafe pointers during root scanning.</p>

<p>This seems almost certain to cause unsound behavior; as noted above,
transmuting <code>Box&lt;T&gt;</code> to <code>*mut T</code> is an ownership transfer, and if
<code>T</code> holds a root, then later code might access it. This means that
the roots owned by <code>T</code> need to be scanned, to keep their associated
objects on the GC Heap alive.</p></li>
<li><p>Punt the question: if a program uses GC, any use of unsafe pointers
(as local variables or as members of structures) needs some sort of
attribute or annotation that tells the GC how to interpret the value
held in the unsafe pointer.</p>

<p>This would be quite difficult to put into practice. <a href="/blog/2015/11/10/gc-and-rust-part-1-specing-the-problem/">Part 1</a>
included a <a href="/blog/2015/11/10/gc-and-rust-part-1-specing-the-problem/#modularity">&ldquo;Modularity&rdquo; goal</a>:</p>

<blockquote><p>A Rust program that uses GC should be able to link to a crate
whose source code was authored without knowledge of GC.</p></blockquote>

<p>Requiring annotations on
every use of unsafe pointers means sacrificing this goal.</p></li>
<li><p>Treat unsafe pointers as potential root owners: Traverse them
and use their type as the basis for the scan.</p>

<p>This seems like the most reasonable option. But, can the types
of unsafe pointers be trusted?</p></li>
</ul>


<a name="Is.the.meta-data.trustworthy."></a>
<h2>Is the meta-data trustworthy?</h2>

<p>We assumed the existence of stack and type maps.
But where do they come from?</p>

<p>These maps need to be generated by the <code>rustc</code> compiler; after all,
they rely on low-level details of the generated code, such as the
offsets of fields within types, the offsets of local variables in a
stack frame, or the addresses of function call-sites.</p>

<p>The <code>rustc</code> compiler, in turn, is going to generate the information
based on the source code text. So far, so good.</p>

<p>Here&rsquo;s the rub: we assumed that the stack map will tell us the types
we need for all local variables of interest for all frames on the call
stack.</p>

<p>But in practice, a value can be <em>cast</em> to a different type.</p>

<p>In particular, in today&rsquo;s Rust 1.x, it is considered <em>safe</em> to cast
between <code>*mut T</code> and <code>*mut U</code> for any <code>T</code> and <code>U</code>:</p>

<pre><code class="rust">fn main() {
    let b = Box::new("peanut butter"); // (imagine if this held rooted data)
    let mut p = Box::into_raw(b);
    let pb = p as *mut String; // bogus type, but safe
    p = Box::into_raw(Box::new("jelly"));
    // this is where a potential GC would be worrisome
    println!("p: {:?} p2: {:?}", p, pb);

    // (just demonstrating recovery of original value via unsafe code)
    let pb = pb as *mut &amp;'static str;
    let recover = unsafe { Box::from_raw(pb) };
    println!("recovered: {:?}", recover);
}
</code></pre>

<p>This is a real problem, in terms of the goals we have set up for ourselves.
100% modular GC requires that we be able to link with code that does things
like the above with the owners of its roots, and that includes when the roots
are indirectly held in boxes on the Rust Heap.</p>

<p>We may be able to add constraints on the <code>Gc&lt;T&gt;</code> type to prevent such things
from occurring when the types are apparent (e.g. when one is working with a
local variable of type <code>Gc&lt;T&gt;</code>). But in general, the types will
not be apparent to the code performing the cast; in particular,
we would still need to address type-parametric code that performs
such casts of unsafe pointers.</p>

<a name="Solutions"></a>
<h2>Solutions</h2>

<p>What can we do about these problems?</p>

<p>One obvious response to the untrustworthy meta-data problem would be to change the language and make casts from <code>*T</code> to <code>*U</code>
<em>unsafe</em>.<label for='&lsquo;unsafe-casts&rsquo;' class='margin-toggle sidenote-number'></label><input type='checkbox' id='&lsquo;unsafe-casts&rsquo;' class='margin-toggle'/><span class='sidenote'>&lsquo;Indeed, </span>
 This would deal with the problem at a surface level, in the sense that
we would be able to at least allow a program using GC to link to a
GC-oblivious crate if the latter crate did not use any <code>unsafe</code>
blocks.
But it would not be terribly satisfactory; we want Rust&rsquo;s
solution for GC to be able to link to as many crates as possible, and
ruling out all code that does any cast of an unsafe pointer seems quite limiting.</p>

<p>We could also revise the set of goals, e.g. scale back our ambitions
with respect to compositionality, and return to ideas like having the
roots constrained to stack, as <a href="#Roots.Constrained.To.Stack..Option.2.">discussed above</a>.</p>

<p>An alternative solution I have been considering is to try to adopt a
hybrid approach for root scanning: use stack maps for the local
variables, but also have the allocator inject tracing meta-data onto
the objects allocated on the Rust Heap, and do a kind of conservative
scanning, but <em>solely</em> for finding roots embeded in objects on the
Rust Heap. This way, unsafe casts might become irrelevant: when
encountering <em>any</em> native pointer (e.g. <code>*mut u8</code>), we would ignore
the referenced type and instead look up whether it is an object on the
Rust Heap, and if so, extract the allocator-injected tracing
information.</p>

<p>I plan to dive more deeply into discussing solutions in a follow-up post.
This post is already quite long, but more importantly, I want to get some
concrete data first on the overheads imposed by the metadata injected during
allocation in state of the art conservative GC&rsquo;s like <a href="http://www.hboehm.info/gc/">BDW</a>.</p>

<hr />

<p>Oh, and finally (but completely unrelated): Happy 2016 to all the hackers out there!
Hope that you copied over all your live objects from 2015!</p>

<script>
// ## References
//
// * [On LLVM’s GC Infrastructure][on-llvms-gc]
//
// * [Compiler Support for Garbage Collection in a Statically Typed Language][diwan-moss-hudson]
</script>



]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Surfaces and Signatures: Component Privacy versus Dependence]]></title>
    <link href="http://blog.pnkfx.org/blog/2015/12/19/signatures-and-surfaces-thoughts-on-privacy-versus-dependency/"/>
    <updated>2015-12-19T22:30:00+01:00</updated>
    <id>http://blog.pnkfx.org/blog/2015/12/19/signatures-and-surfaces-thoughts-on-privacy-versus-dependency</id>
    <content type="html"><![CDATA[<p>I have had some thoughts on what <em>privacy</em> is used for in programming
languages, and how it differs from the notion of <em>dependence</em> between
modules (or at least compilation units) in a language like Rust.
And I thought I should share.</p>

<!-- more -->


<p>I have been working on an
RFC<label for='&lsquo;arr-eff-what&rsquo;' class='margin-toggle sidenote-number'></label><input type='checkbox' id='&lsquo;arr-eff-what&rsquo;' class='margin-toggle'/><span class='sidenote'>&lsquo;<a </span>
meant to increase the expressiveness of Rust&rsquo;s privacy construct
(the <code>pub</code> modifier), and in the process hopefully simplify the mental
model for what privacy means there.</p>

<p>However, I kept finding myself diving into regressions in my draft RFC
document: idealized hypothetical semantics for privacy, and
discussions of what motivates different aspects of that semantics.</p>

<p>Eventually I realized that such text was going to really bog down the
RFC itself (which is meant to describe a relatively simple language
change);
so I decided it was time for a blog
post<label for='&lsquo;gc-posts&rsquo;' class='margin-toggle sidenote-number'></label><input type='checkbox' id='&lsquo;gc-posts&rsquo;' class='margin-toggle'/><span class='sidenote'>&lsquo;Yes, </span>,
if for no other reason than to provide a place for me to cut-and-paste
all those digressions.</p>

<p><label for='' class='margin-toggle'>&#8853;</label><input type='checkbox' id='' class='margin-toggle'/><span class='marginnote'>
Bugs including:
&ldquo;Trait re-exports fail due to privacy of containing module&rdquo; (<a href="https://github.com/rust-lang/rust/issues/18241">#18241</a>),
&ldquo;Rules governing references to private types in public APIs not enforced in impls&rdquo; (<a href="https://github.com/rust-lang/rust/issues/28325">#28325</a>)
&ldquo;Type alias can be used to bypass privacy check&rdquo; (<a href="https://github.com/rust-lang/rust/issues/28450">#28450</a>),
&ldquo;Private trait&rsquo;s methods reachable through a public supertrait&rdquo; (<a href="https://github.com/rust-lang/rust/issues/28514">#28514</a>),
&ldquo;Non-exported type in exported type signature does not error&rdquo; (<a href="https://github.com/rust-lang/rust/issues/29668">#29668</a>),
</span>
There are a number of bugs that have been filed against the privacy
checking in Rust; some are simply implementation issues, but the
comment threads in the issues make it clear that in some cases,
different people have very different mental models about how privacy
interacts with aliases (e.g. <code>type</code> declarations) and re-exports.</p>

<p>The existing privacy rules in Rust try to enforce two things:</p>

<ol>
<li><p>When an item references a path, all of the names on that path need to
be visible (in terms of privacy) in the referencing context, and,</p></li>
<li><p>Private items should not be exposed in the surface of public API&rsquo;s.</p></li>
</ol>


<p>One might reasonably ask: What do I mean by &ldquo;visible&rdquo;, or &ldquo;surface&rdquo;?</p>

<p>For Rust today, &ldquo;visible&rdquo; means &ldquo;either (1.) public, via <code>pub</code>, (2.)
defined in the current module, or (3.) defined in a parent of the
current module.&rdquo;</p>

<p>But &ldquo;surface&rdquo; is a bit more subtle, and before we discuss it, I want
to talk a bit about the purpose of &ldquo;visibility&rdquo; in the first place.</p>

<a name="Digression:.a.dependence.need.not.be.visible"></a>
<h2>Digression: a dependence need not be visible</h2>

<p>In a hypothetical idealized programming language (<em>not</em> Rust), and
under a particularly extreme reading of the term &ldquo;private&rdquo;, changes to
definitions that are private to one module would have no effect on the
validity of pre-existing uses from other modules. Another way of
looking at this: changes to private definitions in one compilation
unit would not require other compilation units to be recompiled, and
will not cause programs that previously type-checked to stop
type-checking.</p>

<p>One form of this ideal is the following:</p>

<script src="http://blog.pnkfx.org/javascripts/viz.js" charset="utf-8"></script>


<div id="extreme_private_calls"></div>


<script>
    var dot_source = 'digraph { rankdir="LR"; bgcolor="transparent"; node [shape="rect"]; subgraph cluster_1 { fn_a [label="pub fn a()"]; label="unit1"; } subgraph cluster_2 { fn_b [label="pub fn b()"]; fn_c [label="fn c()"]; fn_b -> fn_c [label="calls"]; label="unit2"; } fn_a -> fn_b [label="calls"]; }';
    var elem = document.getElementById("extreme_private_calls");
    elem.innerHTML = Viz(dot_source, "svg");
</script>


<p>In this picture, one can see that the <code>fn c()</code> is a private component
of &ldquo;unit2&rdquo;: it may just be an implementation detail of the body of
<code>pub fn b()</code>, that the author of &ldquo;unit2&rdquo; can revise at will or
eliminate entirely, without requiring any changes to &ldquo;unit1&rdquo;
downstream.</p>

<p>A problem arises when one sees other kinds of composition, at least in
language like Rust, where values are directly embedded into their
containers.  For example, instead of function calls, imagine type
definitions:</p>

<script src="http://blog.pnkfx.org/javascripts/viz.js" charset="utf-8"></script>


<div id="extreme_private_types"></div>


<script>
    var dot_source = 'digraph { rankdir="LR"; bgcolor="transparent"; node [shape="rect"]; subgraph cluster_1 { struct_a [label="pub struct A { \\l    b: unit2::B \\l}\\l"]; label="unit1"; } subgraph cluster_2 { struct_b [label="pub struct B { \\l    c: C \\l}\\l"]; struct_c [label="struct C {\\l    x: i32,\\l    y: i32\\l}\\l"]; label="unit2"; } struct_a -> struct_b [label="uses"]; struct_b -> struct_c[label="uses", constraint=false] }';
    var elem = document.getElementById("extreme_private_types");
    elem.innerHTML = Viz(dot_source, "svg");
</script>


<p><label for='' class='margin-toggle'>&#8853;</label><input type='checkbox' id='' class='margin-toggle'/><span class='marginnote'>
In many other languages (e.g. Java, ML, Scheme), such
changes do not require recompiling the downstream crate, because
the members of structural types are just <em>references</em> to other heap-allocated
values, rather than being directly embedded in the allocated structure.
</span>
In this situation, even though the <code>struct C</code> is not publicly
accessible outside of &ldquo;unit2&rdquo;, changes to <code>struct C</code> will still
require the downstream &ldquo;unit1&rdquo; to be recompiled (because the contents
of <code>struct A</code>, and thus its size in bytes, may have changed along with
<code>struct C</code>).</p>

<p>So, what does it <em>mean</em> that <code>C</code> is &ldquo;private&rdquo;, if there is still a
dependence from the contents of &ldquo;unit1&rdquo; on the supposedly private
definition of <code>struct C</code>?</p>

<p>My answer to this is to distinguish between <em>visibility</em> versus <em>dependency</em>.</p>

<p>In the above picture, <code>struct A</code> in &ldquo;unit1&rdquo; has a dependence on the
definition of <code>struct C</code> in &ldquo;unit2&rdquo;. But <code>struct C</code> remains
<em>invisible</em> to <code>struct A</code>, in the sense that one cannot actually write
a direct reference to that type in the context of &ldquo;unit1.&rdquo;</p>

<a name="What.is.visibility.for."></a>
<h2>What is visibility for?</h2>

<p>Some basic definitions: An item is just as it is declared in the Rust
<a href="https://doc.rust-lang.org/reference.html#items">reference manual</a>: a component of a crate, located at a fixed path
(potentially at the &ldquo;outermost&rdquo; anonymous module) within the module
tree of the crate.</p>

<p>Every item can be thought of as having some hidden implementation
component(s) along with an exposed surface API.</p>

<p>So, for example, in:
<code>rust
pub fn foo(x: Input) -&gt; Output { Body }
</code>
the surface of <code>fn foo</code> includes <code>Input</code> and <code>Output</code>, while the <code>Body</code> is
hidden.</p>

<p>What I would like is to establish the following
invariant<label for='&lsquo;inv&rsquo;' class='margin-toggle'> &#8853;</label><input type='checkbox' id='&lsquo;inv&rsquo;' class='margin-toggle'/><span class='marginnote'>&lsquo;Yes, </span>
for the language: if an item <code>I</code> is accessible in context <code>C</code>, then the
surface for <code>I</code> does not expose anything that is inaccessible to <code>C</code>.</p>

<a name="Intuition.behind.what..surface..means"></a>
<h2>Intuition behind what &ldquo;surface&rdquo; means</h2>

<p>I am taking care to distinguish between the phrase &ldquo;exposed surface
API&rdquo; (more simply put, &ldquo;surface API&rdquo; or just &ldquo;surface&rdquo;), versus the
more common unqualified phrase &ldquo;API&rdquo;, because some items have
components that I argue are part of the item&rsquo;s programming interface,
but are not part of the publicly exposed surface of the item (further
discussed in a <a href="#Why.is.a..surface..not.the.same.as.a.signature.">later section</a>).</p>

<p>The inutition behind the term &ldquo;surface&rdquo; is this:
The exposed surface of an item is all of the
components<label for='&lsquo;surface-components&rsquo;' class='margin-toggle'> &#8853;</label><input type='checkbox' id='&lsquo;surface-components&rsquo;' class='margin-toggle'/><span class='marginnote'>&lsquo;&ldquo;components&rdquo; </span>
 that the client operation&rsquo;s context must be able to reference to in order to use this
item legally.</p>

<p>There are two halves to this, that are roughly analogous to the output
and input types of a function: ensuring that local reasoning holds,
and ensuring an interface is actually usable.</p>

<a name="Restricting.output.surface.enables.local.reasoning"></a>
<h3>Restricting output surface enables local reasoning</h3>

<p>A function&rsquo;s return type is part of its exposed surface, because if
a module has decided that a type <code>T</code> should be inaccessible in some
outer context <code>C</code>, then we do not want a value of that type to flow
into <code>C</code> while still having the type
<code>T</code>.<label for='&lsquo;boxes&rsquo;' class='margin-toggle'> &#8853;</label><input type='checkbox' id='&lsquo;boxes&rsquo;' class='margin-toggle'/><span class='marginnote'>&lsquo;Of </span></p>

<p>In other words, we wish to reject such code in order to enable
module authors to employ <em>local reasoning</em> about all possible
locations in the source code that the operations on instances of
<code>T</code> could be invoked.</p>

<p>This <em>is</em> a soundness criteria: People need to be able to employ
this kind of reasoning.</p>

<a name="Restricting.input.surface.catches.API.mistakes"></a>
<h3>Restricting input surface catches API mistakes</h3>

<p>A function&rsquo;s input types are part of its exposed surface, because
without access to such types, the function is not callable.</p>

<p>In other words, we wish to reject such code in order to catch bugs
where a crate is <em>accidentally providing</em> a function without realizing
that it cannot actually be used in the contexts that the author wants
it available in.</p>

<p>This is not a soundness criteria; it is just a language usability one.<label for='&lsquo;prioritizing-halves&rsquo;' class='margin-toggle'> &#8853;</label><input type='checkbox' id='&lsquo;prioritizing-halves&rsquo;' class='margin-toggle'/><span class='marginnote'>&lsquo;In </span></p>

<a name="Why.is.a..surface..not.the.same.as.a.signature."></a>
<h2>Why is a &ldquo;surface&rdquo; not the same as a signature?</h2>

<p>Intuitively, one might ask: &ldquo;well, this is easy: the <em>signature</em> of
<code>fn foo</code> is <code>fn (Input) -&gt; Output</code>; does that not suffice as the
description of the <em>surface</em> of <code>fn foo</code>?&rdquo;</p>

<p>I am distinguishing the above notion of &ldquo;surface&rdquo; from the idea of a
&ldquo;signature&rdquo;, for the following reason: To my mind, the signature
(e.g. of a type or a function) contains all of the meta-data needed to
check (in the current crate or in other crates) whether a item is
being used properly. Such a signature may include references to names
that are not actually accessible in the current context. Compare this
to the <em>surface</em>, which is the subset of the names of the signature
that <em>must</em> be accessible in any context where the item is itself
accessible.</p>

<p>One example of where this kind of thinking can be applied is
<code>where</code> clauses. A where-clause can reference things that are not
accessible outside of the module of the function.  I would consider
such a <code>where</code> clause to still be part of the function&rsquo;s signature
(e.g., I would expect the compiler to reject my attempt to call the
function if I violate the encoded constraint), but I do not
necessarily consider the types or traits within that where clause part
of the surface API, since there are hidden parts to the constraint
that I do not have access to in my calling module.</p>

<p>Here is a concrete example that runs in Rust 1.5:</p>

<pre><code class="rust">mod a {
    struct S(&amp;'static str);                 // private struct type S
    pub trait Trait { fn compute(&amp;self) -&gt; i32; }

    impl Trait for (i32, S) {
        fn compute(&amp;self) -&gt; i32 { self.0 + ((self.1).0.len() as i32) }
    }

    pub fn foo&lt;X&gt;(x: X) -&gt; i32
        where (X, S): Trait // where clause refers to private type S
    {
        (x,S("hi")).compute()
    }
}

fn main() {
    println!("{}", a::foo(3));
}
</code></pre>

<p>There are other examples that we may want to support in the future.
For example, Rust (version 1.5) considers bounding a type parameter
directly via a private trait to be illegal, but we might reasonably
revise the rules to say that while such a bound is part of the
signature, it need not be part of the <em>surface</em>.</p>

<p>(A very similar construction is allowed in Rust 1.5: A <code>pub</code> trait
can have a private <em>parent</em> trait, which allows us to encode the
latter construction anyway: the surface area of a function does not
include the parent traits of bounds on its type parameters.)</p>

<p>That&rsquo;s a lot of text to read. Here is the kind of code I am talking
about:</p>

<pre><code class="rust">mod a {
    struct S(String);                      // private type
    trait Trait { fn make_s(&amp;self) -&gt; S; } // private trait
    pub trait SubT: Trait { }              // public trait to placate rustc

    pub fn foo&lt;X:SubT&gt;(x: X) { // public fn that external code *can* use.
        let s: S = x.make_s();
        s.do_stuff();
    }

    // Impl trait for both () and i32, so clients can call `foo` on () or i32.
    impl Trait for () { fn make_s(&amp;self) -&gt; S { S(format!("():()")) } }
    impl Trait for i32 { fn make_s(&amp;self) -&gt; S { S(format!("{}:i32", self)) } }
    impl SubT for () {}
    impl SubT for i32 {}

    impl S { fn do_stuff(&amp;self) { println!("stuff with {}", self.0); } }
}

fn main() {
    a::foo(());
    a::foo(3);
}
</code></pre>

<p>In short: the term &ldquo;surface API&rdquo; here is <em>not</em> synonymous with the
term &ldquo;signature&rdquo;.</p>

<p>Assuming that you believe me that this new term, &ldquo;surface API&rdquo;, is
actually warranted, you might now ask: &ldquo;How does one determine the
surface API of an item?&rdquo; That is one of those questions that may sound
trivial at first, but it is actually a bit subtle.</p>

<p>Let us explore.</p>

<a name="Some.items.can.change.their.surface.based.on.context"></a>
<h3>Some items can change their surface based on context</h3>

<p>For some items, such as <code>fn</code> definitions, the surface API is the same
regardless of the context of where the item is used; for example, if a
function is visible to you, then its surface API is simply its
argument and return types, regardless of from where the function is
referenced.</p>

<p>However, the previous rule does not generally hold for most items; in
general, the exposed surface of a given item is dependent on the
context where that item is referenced.</p>

<p>The main examples of this are:</p>

<p><label for='' class='margin-toggle'>&#8853;</label><input type='checkbox' id='' class='margin-toggle'/><span class='marginnote'>
All of these bullets are phrased as &ldquo;can be hidden&rdquo;, i.e.,
the visibility may be restricted. However, in Rust today,
one can write: <code>mod a{struct X{pub y: i32}}</code>
I may want to generalize the statements here. (Then again, I
am not clear whether there is any way to actually <em>use</em> the
<code>y</code> field that has been exposed in this way.)
</span></p>

<ul>
<li><p><code>struct</code> fields can be hidden in a <code>struct</code>,</p></li>
<li><p>inherent methods can be hidden relative to the type they are attached to, and</p></li>
<li><p>items can be hidden in a <code>mod</code>.</p></li>
</ul>


<p>In all cases where a surface component can be hidden in this
context-dependent fashion, there is an associated <code>pub</code>-modifier
present on the definition of that component.</p>

<p>As an example of how the surface of a <code>struct</code> is context dependent,
the following is legal:</p>

<pre><code class="rust">mod a {
    #[derive(Default)]
    struct Priv(i32);

    pub mod b {
        #[derive(Default)]
        pub struct F {
            pub    x: i32,
                   y: ::a::Priv,
        }

        // ... accesses to F.{x,y} ...
    }
    // ... accesses to F.x ...
}

mod k {
  use a::b::F;
  // ... accesses to F and F.x ...
}
</code></pre>

<p>Within <code>mod b</code>, the surface API of <code>F</code> includes both the fields <code>x</code>
and <code>y</code>, which means that the use of the type <code>Priv</code> is okay, since
that is accessible from the context of <code>mod b</code>.</p>

<p>Elsewhere, such as within <code>mod k</code>, the surface API of <code>F</code> is just the
field <code>x</code>. But this is again okay, because the type of <code>x: i32</code> is
visible everywhere.</p>

<a name="Aliases.and.translucency"></a>
<h3>Aliases and translucency</h3>

<p>Some items, such as <code>type</code> aliases, <code>const</code> definitions, or rebinding
imports a la <code>use &lt;path&gt; as &lt;ident&gt;</code>, can act to introduce named aliases
to an item.</p>

<p>In such cases, the alias itself has its own associated visibility:</p>

<pre><code class="rust">mod a {
    pub struct S(String); // public type
    type Alias1 = S;      // private alias to the type
}

pub use a::S as Alias2;   // public alias to the type
</code></pre>

<p>The surface of simple aliases is also simple: the surface of an
alias
is just the paths referenced on its right-hand side.</p>

<p>As a small additional wrinkle, type aliases can be type-parametric. In
general, the exposed surface of a type alias are the bounds on its
type parameters, plus the paths referenced on its left-hand side.</p>

<p>So, for example, according to the rules today:</p>

<pre><code class="rust">mod bad_aliases {
    struct Private1(String); // private type
    pub type PubAlias1 = Private1; // ERROR: private type exposed in pub surface

    trait PrivateTrait { }
    pub type PubAlias2&lt;X:PrivateTrait&gt; = i32; // ERROR: private trait exposed in pub surface
}
</code></pre>

<p>The more interesting issue is how <em>other</em> surface APIs are influenced
when they reference an alias.</p>

<p>For example:</p>

<pre><code class="rust">mod a {
    pub struct S(String); // public type
    type Alias1 = S;      // private alias to the type

    pub fn twice(s: Alias1) -&gt; String { s.0 }
    //              ~~~~~~
    //                 |
    // Should a `pub fn` be able to reference a private alias,
    // if it points to a suitably public type (like `S` here)?
}

pub use a::S as Alias2;   // public alias to the type
</code></pre>

<p>Should it be legal for us to publicly export <code>fn twice</code> from <code>mod a</code>,
even though it&rsquo;s signature references a private type alias?</p>

<p>The language team recently <a href="https://github.com/rust-lang/rust/pull/29973#issuecomment-165723770">debated</a> this topic, because
it was suggested that allowing this would <a href="https://github.com/rust-lang/rust/pull/29973#issuecomment-158686899">reduce breakage</a>
from a pull request.</p>

<p>The conclusion for now was to continue to disallow the reference to
the private alias in the signature of a public function.</p>

<p>However, there are similar cases that <em>are</em> allowed today (also
discussed on that same PR), mainly involving references to <code>const</code> paths
from types in such signatures.</p>

<pre><code class="rust">mod a {
    const LEN: usize = 4;
    pub fn max(a: [i32; LEN]) -&gt; i32 { a.iter().map(|i|*i).max().unwrap() }
    //                  ~~~
    //                   |
    // A reference to a private const in a public signature
    // is legal in Rust today.
}

fn main() {
    println!("{}", a::max([1,4,2,3]));
}
</code></pre>

<p>I have not made up my mind as to which option would be better here.
We may decide to leave things as they are, or loosen the rules for
type aliases (so that they act more like <code>const</code> in the latter code),
or we may tighten the rules for references to <code>const</code> (so that one
would have to make <code>LEN</code> in the above code <code>pub</code>).</p>

<p>Regardless of what path we take, I think it makes sense today for the
language specification to at least identify a high-level abstraction
here, rather than dealing with each alias-creating form like <code>type</code> or
<code>const</code> or <code>use</code> individually in an ad-hoc manner.</p>

<p>Namely, I want to pin down the idea of a <em>translucent name</em>. Such a
name is not part of the API surface where it occurs; instead, an
occurrence adds the surface of the alias statement itself to the API
surface.</p>

<p>So, as another artifical example, if we were to change the language so
that <code>type</code> aliases were <em>translucent</em> when determining the exposed
surface of an API, then we might have the following:</p>

<pre><code class="rust">mod a { // (not legal Rust today)
    pub struct S(String); // public type
    pub trait Bound { type X; fn trait_method(&amp;self) -&gt; Self::X; }
    impl Bound for String { type X = String; fn trait_method(&amp;self) -&gt; String { self.clone() } }
    impl Bound for S { type X = String; fn trait_method(&amp;self) -&gt; String { self.0.clone() } }

    type Alias&lt;T: Bound&gt; = (T, T::X, S); // private Alias, with surface = {Bound, S}

    pub fn free_fun&lt;T: Bound&lt;X=String&gt;&gt;(a: Alias&lt;T&gt;) -&gt; String
    //                 ~~~~~   ~~~~~~      ~~~~~        ~~~~~~
    //  free_fun has     |       |           |            |
    //     surface = { Bound, String, surface(Alias), String }
    //             = { Bound, String,    Bound, S   , String }
    //             = { Bound, S, String }
    //
    // which is compatible with `free_fn` being `pub`, because
    // `Bound`, `S`, and `String` are all `pub`.
    {
        format!("{}{}", a.0.trait_method(), (a.1).0)
    }
}
</code></pre>

<p>Note 1: Even though <code>Alias</code> is type-parameteric over <code>T</code>, that
parameter would not be considered part of its surface. Anyone using
the alias would have to have access to whatever type they plugged in
there, of course.</p>

<p>Note 2: Type parameter bounds not enforced on type aliases in Rust yet.</p>

<p>This computation and questions here would become a little more
interesting if we had restricted visibility access modifiers on
associated items in traits. However, we do not have to consider it:
All associated items are implicitly <code>pub</code>, and so we do not need to
worry about whether the <code>X</code> in a projection like <code>T::X</code> is visible.
All that matters is whether the trait <code>Bound</code> itself is visible (which
is already reflected in the surfaces where <code>Bound</code> is used).</p>

<a name="Conclusion"></a>
<h2>Conclusion</h2>

<p>Okay, that was of a bit of a meandering tour through some
of the issues I have been thinking about.</p>

<p>The big ideas I want to stress are these:</p>

<ul>
<li><p>The &ldquo;surface&rdquo; of an item can be different from the &ldquo;signature&rdquo; of
that item.</p></li>
<li><p>Restricting the components in a surface of an item according to the
visibility of that item (1.) enables local reasoning and (2.)
catches API mistakes.</p></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[GC and Rust Part 1: Specifying the Problem]]></title>
    <link href="http://blog.pnkfx.org/blog/2015/11/10/gc-and-rust-part-1-specing-the-problem/"/>
    <updated>2015-11-10T17:45:00-05:00</updated>
    <id>http://blog.pnkfx.org/blog/2015/11/10/gc-and-rust-part-1-specing-the-problem</id>
    <content type="html"><![CDATA[<p>This is the first in a series of posts will discuss why garbage
collection is hard, especially for Rust, and brainstorm about
solutions to the problems we face.</p>

<p>The relationship between garbage collection (GC) and the Rust
programming language has been an interesting one.</p>

<p>GC was originally deeply integrated into the language, complete with
dedicated syntax (good old <code>@T</code> &hellip;). Over time the team found ways to
lessen the dependency on GC, and then finally remove it from the
language entirely.</p>

<p>However, we still want to provide support for garbage collection.</p>

<p>To explain why, I need to define the actual problems we seek to solve.
So let us explore the problem space.</p>

<!-- more -->


<a name="L.....now.you.have..nyh..two.problems"></a>
<h1>&hellip; <a href="http://regex.info/blog/2006-09-15/247">now you have</a> two problems</h1>

<p>(The body of this post makes heavy use of client-side rendering,
because of author idiosyncrasies.  You may need to wait a moment while
the supporting Javascript loads.)</p>

<script src="http://blog.pnkfx.org/javascripts/viz.js" charset="utf-8"></script>


<script src="http://blog.pnkfx.org/javascripts/js_to_dot.js" charset="utf-8"></script>


<script src="http://blog.pnkfx.org/javascripts/gc_rendering.js" charset="utf-8"></script>


<a name="The.Problem.Space"></a>
<h2>The Problem Space</h2>

<p>Now that we have <a href="/blog/2015/10/27/gc-and-rust-part-0-how-does-gc-work/">reviewed</a> what GC is and how it works, let us
discuss what GC could mean to Rust.</p>

<p>I have identified two distinct kinds of support that we could provide:
&ldquo;GC&rdquo; could describe a feature for pure Rust programs, or &ldquo;GC&rdquo; could mean a
3rd-party runtime interoperation feature. Let us discuss each in turn.</p>

<a name="One.GC.shared.by.every.crate"></a>
<h3>One GC shared by every crate</h3>

<p>We could add a smart-pointer to <code>libstd</code>, e.g. a <code>Gc&lt;T&gt;</code> type, that
arbitrary library crates could use as they create or receive instances
of <code>T</code>. The intention here would be similar to how <code>Rc&lt;T&gt;</code> is used:
One does not want to track ownership precisely, but rather treat
ownership as shared amongst all users of a value, and let the runtime
system handle reclaiming the value.</p>

<p>So for example, we might want to write code that looks like this:</p>

<pre><code class="rust">use std::gc::Gc;

struct Cons&lt;T&gt; {
    head: T,
    tail: Cell&lt;Option&lt;Gc&lt;Self&gt;&gt;&gt;,
}

impl&lt;T&gt; Cons&lt;T&gt; {
    fn new(head: T, tail: Option&lt;Gc&lt;Self&gt;&gt;) -&gt; Self {
        Cons { head: head, tail: Cell::new(tail) }
    }
    fn head(&amp;self) -&gt; &amp;T { &amp;self.head }
    fn tail(&amp;self) -&gt; Option&lt;Gc&lt;Self&gt;&gt; { self.tail.get() }
}

#[test]
fn demo() {
    let a;
    let f: Gc&lt;_&gt;;
    {
            a = box Cons::new(1, None);
        let b = box Cons::new(2, Some(a));
        let c = box Cons::new(3, Some(a));
        let d = box Cons::new(4, Some(b));
        let e: Gc&lt;_&gt;;
            e = box Cons::new(a, Some(b));
            f = box Cons::new(c, Some(d));

        let mut g = box Cons::new(10, None);
        let     h = box Cons::new(20, Some(g));
        g.tail.set(Some(h));
    }
    // here, locals `a` and `f` are the roots
}
</code></pre>

<p>(The above snippet assumes we have extended <code>box EXPR</code> to an
overloaded operator in the manner similar to that described in
<a href="https://github.com/rust-lang/rfcs/blob/master/text/0809-box-and-in-for-stdlib.md">RFC 809</a>, so that <code>let g: Gc&lt;_&gt; = box EXPR;</code> works, and that
the type inference figures out that all the locals need to be
in <code>Gc&lt;_&gt;</code>.)</p>

<p>This results in a stack and heap modelled by this picture.</p>

<p id="target_anchor_gc_demo_1" class="fullwidth"></p>


<script>
var stack = { id: "cluster_stack", label: "Stack", is_subgraph: true };
var gc_heap = { id: "cluster_gc_heap", label: "GC Heap", is_subgraph: true, style: "rounded" };
var a = object_record("A", "<head> head: 1 | <tail> tail: None");
var b = object_record("B", "<head> head: 2 | <tail> tail: Some(A)");
var c = object_record("C", "<head> head: 3 | <tail> tail: Some(A)");
var d = object_record("D", "<head> head: 4 | <tail> tail: Some(B)");
var e = object_record("E", "<head> head: A | <tail> tail: Some(B)");
var f = object_record("F", "<head> head: C | <tail> tail: Some(D)");
var g = object_record("G", "<head> head: 10 | <tail> tail: Some(H)");
var h = object_record("H", "<head> head: 20 | <tail> tail: Some(G)");

var local_a = { id: "local_a", label: "a", shape: "record" };
var local_f = { id: "local_f", label: "f", shape: "record" };

stack[1] = local_a;
stack[2] = local_f;

b.tail = edge_from_port(":tail", a);
c.tail = edge_from_port(":tail", a);
d.tail = edge_from_to_ports(":tail", ":id", b);
e.head = edge_from_port(":head", a);
e.tail = edge_from_to_ports(":tail", ":id", b);
f.head = edge_from_to_ports(":head", ":id", c);
f.tail = edge_from_to_ports(":tail", ":id", d);
g.tail = edge_from_to_ports(":tail", ":id", h);
h.tail = edge_from_to_ports(":tail", ":id", g);

local_a.ref = a;
local_f.ref = edge_to_port(":id", f);

gc_heap[0] = a;
gc_heap[1] = b;
gc_heap[2] = c;
gc_heap[3] = d;
gc_heap[4] = e;
gc_heap[5] = f;
gc_heap[6] = g;
gc_heap[7] = h;

var objects = [stack, gc_heap];
post_objects("target_anchor_gc_demo_1", objects, { rankdir:"LR", nodesep:0.2, no_dims:true });
</script>


<p>The GC would be allowed to collect the objects labelled &ldquo;E&rdquo;, &ldquo;G&rdquo;, and
&ldquo;H&rdquo; in the picture, since they are not reachable from the roots.
(However, the GC is not obligated to reclaim them at any particular
time. Usually GC&rsquo;s provide little guarantees about how soon objects
will be reclaimed.)</p>

<p>This kind of feature could be useful in any Rust library.</p>

<a name="Advantages.of.Gc.T..over.Rc.T."></a>
<h4>Advantages of Gc<T> over Rc<T></h4>

<p>The main hypothesized advantages over <code>Gc&lt;T&gt;</code> over <code>Rc&lt;T&gt;</code> are:</p>

<ul>
<li><p><code>Gc&lt;T&gt;</code> is <code>Copy</code>, which makes it possible to construct types like
<code>Cell&lt;Gc&lt;T&gt;&gt;</code>.</p>

<p>(It also has nicer programmer ergonomics in some cases; e.g. some
programmers dislike having to write <code>x.clone()</code> every time they
want to make a copy of ref-counted <code>x</code>.)</p></li>
<li><p><code>Gc&lt;T&gt;</code> allows cyclic structure to be reclaimed (e.g. the objects
 &ldquo;G&rdquo; and &ldquo;H&rdquo; in the picture above.</p></li>
<li><p>Using <code>Gc&lt;T&gt;</code> <em>might</em> have less overhead than <code>Rc&lt;T&gt;</code>: every time
you clone an <code>Rc&lt;T&gt;</code> it incurs reference-count overhead, while
<code>Gc&lt;T&gt;</code> just copies the reference.</p>

<p>(However, this stated advantage must be tempered by the
realization that GC incurs its own separate overheads, as
discussed in the <a href="/blog/2015/10/27/gc-and-rust-part-0-how-does-gc-work/">background post</a>.</p></li>
</ul>


<a name="Drawbacks.of.one.GC.for.everyone"></a>
<h4>Drawbacks of one GC for everyone</h4>

<p>There are two immediate drawbacks with this kind of collector
support.</p>

<p>First, adding it would require that the standard library either
provide a garbage collector (that all clients of <code>Gc&lt;T&gt;</code> would have to
link in), or at least standardize a fixed API that third-party
collector implementations would have to satisfy to support <code>Gc&lt;T&gt;</code>.</p>

<p><label for='' class='margin-toggle'>&#8853;</label><input type='checkbox' id='' class='margin-toggle'/><span class='marginnote'>
In particular, smart-pointers in Rust
require at <em>least</em> support for the <a href="https://doc.rust-lang.org/std/ops/trait.Deref.html"><code>Deref</code> trait</a>, so
that dereferencing expressions like <code>gc_ref.field</code> and
<code>gc_ref.method()</code> are compiled into code that resolves the <code>gc_ref</code> to
a<code>&amp;T</code> reference (and then the subsequent field or method lookup is
performed with respect to that <code>&amp;T</code> reference).
<br></br>
As a reminder, the signature of the <code>deref</code> method, before lifetime
elision, is <code>fn deref&lt;'a&gt;(&amp;'a self) -&gt; &amp;'a Self::Target</code> (and the
associated <code>Target</code> type for <code>Gc&lt;T&gt;</code> would be <code>T</code>).  Thus, the
compiler will ensure that the reference <code>&amp;'a T</code> we extract from the
<code>gc_ref</code> outlive the <code>gc_ref</code> itself; this means that the <code>gc_ref</code>
will be one (of potentially many) root keeping the object from being
reclaimed for the entirety of the lifetime <code>'a</code>, and thus supporting
the <code>Deref</code> trait design on a <code>Gc&lt;T&gt;</code> could work seamlessly on an
entirely non-moving GC.
<br></br>
However, moving objects complicate <code>Deref</code> support; now one needs to
ensure not only that the object remains alive, but also that the
reference <code>&amp;'a T</code> consistently points to the same object that the
original <code>Gc&lt;T&gt;</code> pointed to, and that references to substructure
within the object (e.g. a <code>&amp;Left</code> within a <code>Gc&lt;(Left, Right)&gt;</code> that
has been deref'ed to <code>&amp;(Left, Right)</code>) also retain a consistent view
of the heap structure. Doing this at an acceptable cost is difficult;
I may discuss this more in a future post.
</span>
Second, it is difficult to provide the ergonomics that one expects
from a smart-pointer type analogous to
<code>Rc&lt;T&gt;</code>.</p>

<p>Okay, so that&rsquo;s the outline of the tradeoffs of providing
a &ldquo;GC for everyone&rdquo; in <code>libstd</code>.  What about a more limited
GC feature, where the audience is not &ldquo;every Rust crate&rdquo;, but instead
just the crates linking to a managed runtime.</p>

<a name="GC.as.Interoperation.Feature"></a>
<h3>GC as Interoperation Feature</h3>

<p>GC as an interoperation feature means that Rust would provide
introspective hooks to improve integration with application frameworks
that are using their own garbage collector. One example of this is
Servo&rsquo;s use of the SpiderMonkey Virtual Machine for its Javascript
support.</p>

<p>Servo is relying on SpiderMonkey&rsquo;s garbage collection for memory
management, not only for Javascript values, but even for
<a href="https://blog.mozilla.org/research/2014/08/26/javascript-servos-only-garbage-collector/">native-code DOM objects</a>.</p>

<p>That post describes (unchecked) scenarios where one can end up with
dangling pointers &ndash; that is, they invite unsoundness.  Proper support
for GC-interoperation in Rust could address this; I will discuss this
further down in this post.</p>

<p>Critically, GC-interoperation does not require the same level of
ergonomics that <code>Rc&lt;T&gt;</code> provides. For example, in this context it is
acceptable for <code>Gc&lt;T&gt;</code> to not support <a href="https://doc.rust-lang.org/std/ops/trait.Deref.html"><code>Deref</code></a>.</p>

<p>(Furthermore, in this context, it may even be acceptable to require
unchecked constraints like &ldquo;the programmer must ensure the collector
is not invoked during this extent&rdquo;, or perhaps &ldquo;the programmer must
periodically invoke a call that tells the GC that this is an
acceptable time to do collection work that could move objects.&rdquo;)</p>

<p>Without a <code>Deref</code> trait and with such unchecked requriements, such
interoperation might end up looking something like this:</p>

<pre><code class="rust">fn double_last(x: Gc&lt;Vec&lt;i32&gt;&gt;) {
    unsafe {
        let ptr: *mut Vec&lt;i32&gt; = x.get_ptr();

        // during the extent of this block, it is the responsibility
        // of the double_last author to ensure the GC never gets
        // invoked (i.e., do not do any allocations to the GC'ed heap
        // during this unsafe-block).

        if Some(i) = (*ptr).last_mut() {
            *i = *i * 2;
        }
    }
}
</code></pre>

<p>In this context, interoperation still requires defining a standard
interface that the third-party collector implementation has to conform
with.</p>

<p><label for='' class='margin-toggle'>&#8853;</label><input type='checkbox' id='' class='margin-toggle'/><span class='marginnote'>
In truth, even for a conservative collector like <a href="http://www.hboehm.info/gc/">BDW</a>,
one must do more than just &ldquo;swap in a new <code>#[allocator]</code>&rdquo; to actually
integrate it properly; the current Rust standard library does not
provide a way to intercept thread spawns and register the new
stack associated with each new thread.
<br></br>
I only realized this only <a href="https://github.com/swgillespie/boehm_gc_allocator/issues/2">recently</a>.
</span>
In a simple world (e.g., a conservative collector designed to
interoperate with C/C++, such as <a href="http://www.hboehm.info/gc/">boehm-demers-weiser</a> (BDW)), this
standard interface could be nothing more than just &ldquo;swap in a
different <a href="https://doc.rust-lang.org/nightly/book/custom-allocators.html">#[allocator] crate</a> that your GC provides.&rdquo;</p>

<p>(The actual interface is unlikely to be so
simple, but the point is, there is a wide
design space to be explored here.)</p>

<a name="Interoperation.with.a..black.box..GC"></a>
<h4>Interoperation with a &ldquo;black box&rdquo; GC</h4>

<p>One way to look at the difference between &ldquo;GC for pure Rust programs&rdquo;
versus &ldquo;GC for interoperation&rdquo; is that in the former case, the GC
feels deeply integrated with the language and standard library, while
in the latter case, the GC is clearly the concern of some entity
outside the language (and we are just trying to accommodate it as best
we can).</p>

<p>An extreme instance of a GC that is definitely an entity outside the
language is a case where the whole GC heap is treated like a black
box, and the objects inside the heap are never directly exposed to the
application code outside the box.</p>

<p>For example, one can imagine a virtual machine (VM) interface where
the code outside the VM is never given addresses of objects on the
heap. Instead, such foreign code only has <em>handles</em> that indirectly
point to those objects.</p>

<p id="target_anchor_black_box_gc_1" class="fullwidth"></p>


<script>
var stack = { id: "cluster_stack", label: "Stack", is_subgraph: true };
var rust_heap = { rankdir:"LR", id: "cluster_rust_heap", label: "Rust Heap", is_subgraph: true };
var gc_heap = { id: "cluster_gc_heap", label: "GC Heap", is_subgraph: true, style: "rounded" };
var handles = object_record("handles", "<h2> Y | <h1> X | <h3> X");

var c = object_record("C", "<f0> Gc(X) | <f1> Box(O)");
c.style = "rounded";
var o = object_record("O", "<f0> Handle(2)");
var x = object_record("X", "<f0> 'a' | <f1> next");
var y = object_record("Y", "<f0> 'b' | <f1> next");
var z = object_record("Z", "<f0> 'c' | <f1> (next)");
x.style = "rounded";
y.style = "rounded";
z.style = "rounded";
var local_x = { id: "local_x", label: "handle_x", shape: "record" };
var local_y = { id: "local_y", label: "handle_y", shape: "record" };
var local_o = { id: "local_o", label: "boxed_o", shape: "record" };

x.next = edge_from_to_ports(":f1", ":id:sw", y);
y.next = edge_from_to_ports(":f1", ":id", z);

o.f0 = edge_from_to_ports(":f0", ":h3", handles);

c.f0 = edge_from_to_ports(":f0", ":id", x);
c.f1 = edge_from_to_ports(":f1", ":id", o);

stack[1] = local_x;
stack[2] = local_y;
stack[3] = local_o;

rust_heap[0] = o;
gc_heap[0] = handles;
handles.x1 = edge_from_to_ports(":h1", ":id", x);
handles.y2 = edge_from_to_ports(":h2", ":id", y);
handles.x3 = edge_from_to_ports(":h3", ":id:sw", x);
local_x.handle = edge_to_port(":h1", handles);
local_y.handle = edge_to_port(":h2", handles);
local_o.box = edge_to_port(":id", o);
gc_heap[2] = x;
gc_heap[3] = y;
gc_heap[4] = z;

var objects = [stack, gc_heap, rust_heap];
post_objects("target_anchor_black_box_gc_1", objects, { rankdir:"LR", nodesep:0.2, no_dims: true });
</script>


<p>In this setting, direct references to objects <em>never</em> escape the black
box. Instead, by setting up a level of indirection, the management of
the objects within the GC heap is completely abstracted away.</p>

<p>In a black box GC setting, one would not expose the data structure of
the objects (since they can never be directly addressed
anyway). Instead, one would define functions on handles that extract
the fields and maps them to handles when necessary:</p>

<pre><code class="rust">extern fn handle_data(a: Handle) -&gt; char;
extern fn handle_next(a: Handle) -&gt; Option&lt;Handle&gt;;
extern fn handle_set_next(a: Handle, b: Option&lt;Handle&gt;);

// sample code interacting with the black box GC

// all of these predicates hold of the above heap diagram
assert_eq!(handle_data(handle_x), 'a');
assert_eq!(handle_data(handle_next(handle_y).unwrap()), 'c');
assert!(handle_next(handle_next(handle_y).unwrap()).is_none());

// this changes the heap to match the diagram below.
handle_set_next(handle_x, handle_next(handle_y));
</code></pre>

<p id="target_anchor_black_box_gc_2" class="fullwidth"></p>




<script>
var stack = { id: "cluster_stack", label: "Stack", is_subgraph: true };
var rust_heap = { rankdir:"LR", id: "cluster_rust_heap", label: "Rust Heap", is_subgraph: true };
var gc_heap = { id: "cluster_gc_heap", label: "GC Heap", is_subgraph: true, style: "rounded" };
// var handles = object_record("handles", "<h2> Y | <h1> X | <h3> X | <h4> (temp for Z)");
var handles = object_record("handles", "<h2> Y | <h1> X | <h3> X");

var c = object_record("C", "<f0> Gc(X) | <f1> Box(O)");
c.style = "rounded";
var o = object_record("O", "<f0> Handle(2)");
var x = object_record("X", "<f0> 'a' | <f1> next");
var y = object_record("Y", "<f0> 'b' | <f1> next");
var z = object_record("Z", "<f0> 'c' | <f1> (next)");
x.style = "rounded";
y.style = "rounded";
z.style = "rounded";
var local_x = { id: "local_x", label: "handle_x", shape: "record" };
var local_y = { id: "local_y", label: "handle_y", shape: "record" };
var local_o = { id: "local_o", label: "boxed_o", shape: "record" };

x.next = edge_from_to_ports(":f1", ":id:w", z);
y.next = edge_from_to_ports(":f1", ":id:n", z);

o.f0 = edge_from_to_ports(":f0", ":h3", handles);

c.f0 = edge_from_to_ports(":f0", ":id", x);
c.f1 = edge_from_to_ports(":f1", ":id", o);

stack[1] = local_x;
stack[2] = local_y;
stack[3] = local_o;

rust_heap[0] = o;
gc_heap[0] = handles;
handles.x1 = edge_from_to_ports(":h1", ":id", x);
handles.y2 = edge_from_to_ports(":h2", ":id", y);
handles.x3 = edge_from_to_ports(":h3", ":id:sw", x);
// handles.z4 = edge_from_to_ports(":h4", ":id:sw", z);
local_x.handle = edge_to_port(":h1", handles);
local_y.handle = edge_to_port(":h2", handles);
local_o.box = edge_to_port(":id", o);
gc_heap[2] = x;
gc_heap[3] = y;
gc_heap[4] = z;

var objects = [stack, gc_heap, rust_heap];
post_objects("target_anchor_black_box_gc_2", objects, { rankdir:"LR", nodesep:0.2, no_dims: true });
</script>


<p>In case it isn&rsquo;t clear, supporting interoperation with this kind of
&ldquo;black box&rdquo; GC requires very little from the Rust side; potentially
nothing at all. The object addresses are hidden, so the GC could move
an object and update its address in the handle
array.<label for='&lsquo;handles&rsquo;' class='margin-toggle'> &#8853;</label><input type='checkbox' id='&lsquo;handles&rsquo;' class='margin-toggle'/><span class='marginnote'>&lsquo;If </span></p>

<p>However, this so-called interoperation is also quite limited in
expressiveness. The defining property of the &ldquo;black box&rdquo; GC, the fact
that it does not expose the addresses of the objects held within, also
means that we cannot expose <code>&amp;</code>-references to the objects or the state
within them, which means we cannot use these objects with the large
number of Rust functions that operate on <code>&amp;</code>-references and slices.</p>

<a name="Digression.on.limits.of..black.box..GC"></a>
<h3>Digression on limits of &ldquo;black box&rdquo; GC</h3>

<p>In addition to the limits regarding exposure of <code>&amp;</code>-references
described above, another issue with &ldquo;black box&rdquo; GC is that
it is not clear whether client code hooking
into the &ldquo;black box&rdquo; GC would be able to instantiate the GC objects
with its own types.</p>

<p>For example, one might think that the objects in the GC heap could be
defined via type parameterization: <code>fn bbox_gc_alloc&lt;T&gt;(t: T) -&gt; Handle;</code>
would create an object on the heap, copy <code>t</code> into it, and return a
handle to that object.</p>

<p>For this to work, the layout of the list cells in the GC heap above
would need to look something like this:</p>

<pre><code class="rust">struct Cons&lt;T&gt; {
    data: T,
    next: Option&lt;GcPtr&lt;Cons&lt;T&gt;&gt;&gt;,
}
</code></pre>

<p>Then constructing a list like the &ldquo;X, Y, Z&rdquo; in the heap diagrams
above would look like:</p>

<pre><code class="rust">let handle_z = bbox_gc_alloc(Cons { data: 'c', next: None });
let handle_y = bbox_gc_alloc(Cons { data: 'b', next: None });
let handle_x = bbox_gc_alloc(Cons { data: 'a', next: None });
handle_set_next(handle_y, handle_z);
handle_set_next(handle_x, handle_y);
</code></pre>

<p>But there are two (related) problems:</p>

<ol>
<li><p>How does one instantiate values that <em>unconditionally</em> hold
 pointers to GC objects.  (For example, how do we allocate an
 instance of <code>Cons&lt;GcPtr&lt;Cons&lt;char&gt;&gt;&gt;</code>?)
 <br></br>
 We have already established that the address in the GC Heap are
 not exposed outside of the heap, so the approach of passing in an
 <code>T</code> value that we used with <code>bbox_gc_alloc</code> above will not work,
 because we cannot put our hands on a <code>GcPtr</code> to use for the
 <code>data</code> field.</p></li>
<li><p>How do we get from the <code>struct</code> definition for <code>Cons</code> to
 the family of methods defined in terms of <code>Handle</code>?
 <br></br>
 Every occurrence of <code>GcPtr</code> used for the struct (as seen from
 the point of view of the GC Heap) needs to be mapped to
 a <code>Handle</code> in the functions exposed to the functions outside
 of GC Heap.</p></li>
</ol>


<p>Also, the hidden object addresses may complicate client code trying to
instantiate GC objects with its own types.</p>

<p>It could be that there is a solution to the problem lurking here.
In any case, interoperation with a blackbox GC is not a primary goal,
since the level of indirection and (perhaps more crucially)
the maintenance of the handles array are not ideal.</p>

<a name="Objectives.and.Requirements..oh.no..now.five.problems."></a>
<h2>Objectives and Requirements (oh no, now five problems)</h2>

<p>The two (or perhaps three) kinds of support described above are
distinct features; there is overlap between them, but trying to find a
single solution that solves both problems completely may not be
possible, and in any case we do not want to wait for that single
solution to be discovered.</p>

<p>Since <code>Rc&lt;T&gt;</code> is already a workable solution for many (though not all)
use cases of <code>Gc&lt;T&gt;</code>, the above idealized &ldquo;one GC shared by every
crate&rdquo; is not a main priority right now (and may never be added to the
Rust language).</p>

<p>Let us focus on GC as an interop feature, and dive into what we would
want to get out of it.</p>

<p>There are a number of objectives for Rust/GC integration that are
worth noting, which I will list here and then define and discuss
below.</p>

<ol>
<li><a href="#safety">Safe</a></li>
<li><a href="#modularity">Modular</a></li>
<li><a href="#zero-cost">Zero-Cost</a></li>
<li><a href="#compositionality">Compositional</a></li>
<li><a href="#precision">Precise (Space-Efficient)</a></li>
</ol>


<a name="L.span.id..safety..Safety.with.respect.to.GC..span."></a>
<h3><span id="safety">Safety with respect to GC</span></h3>

<p>If a Rust crate does not use <code>unsafe</code> constructs (<code>unsafe</code> blocks,
attributes or types with &ldquo;unsafe&rdquo; in their name, etc.), then linking
it with a sound set of crates that use GC must maintain soundness.</p>

<p>In other words, linking in a crate that uses no <code>unsafe</code> construct
should not inject any dereferences of dangling pointers, nor any data
races.</p>

<p>By the way, we absolutely do need to provide criteria that says what
<code>unsafe</code> code <em>is</em> allowed to do when linked with a crate that uses
GC. I am going to assume for these initial posts that we will solve
that problem eventually, but not attempt to address it at the outset.</p>

<a name="L.span.id..modularity..Modularity.with.respect.to.GC..span."></a>
<h3><span id="modularity">Modularity with respect to GC</span></h3>

<p>A Rust program that uses GC should be able to link to a crate whose
source code was authored without knowledge of GC.</p>

<p>For example, if I make a parsing library today that works on string
slices <code>&amp;str</code>, you should be able to link that parsing library into a
program that uses GC, without having to worry about whether the
parsing library carries hidden requirements that invalidate
assumptions made by the GC.</p>

<p>Note: A crate being &ldquo;authored without knowledge of GC&rdquo; is a
property of the source code, not the generated object code. Given
such a crate, the Rust compiler may itself inject metadata
related to GC, such as descriptions of object layout, or
automatically-generated code that dictate how objects should
traced by the collector.</p>

<p>Note: A crate being &ldquo;authored without knowledge of GC&rdquo; is entirely
distinct a crate not supporting GC. That is, we may add well a way for
a crate to declare that it is not compatible with GC. (This would
count as having knowledge of GC; in fact, enough knowledge to know, or
at least guess, that its presence would cause the GC to break, or vice
versa.)</p>

<p>If we cannot satisfy this requirement, then the addition of GC
will, at best, split the growing space of library crates (such as
those available on <a href="https://crates.io/">crates.io</a>) into two disjoint
sub-communities: crates that support GC, and those that do not
(since the latter were written without accounting for the
potential presence of a GC).</p>

<p>An aside: I would really like to find a way to combine the
descriptions of &ldquo;modularity&rdquo; and &ldquo;safety&rdquo;, since they seem to be
attempted to express similar or related objectives.</p>

<p>A final note: There are some features available to crates, such as
requiring a specific low-level allocator, that are likely to be
incompatible with a program that uses GC. We need to define these
caveats and incorporate them into the above definition of
&ldquo;modularity&rdquo;, without weakening it to the point of uselessness.
(However, I will not attempt to tackle that here.)</p>

<a name="L.span.id..zero-cost..Zero-Cost.GC..span."></a>
<h3><span id="zero-cost">Zero-Cost GC</span></h3>

<p>If you don&rsquo;t use the GC feature (in whatever form it takes), your code
should not pay for it.</p>

<p>This applies to the quality of the generated code (in execution
time and code size), and also to the source code, with respect to
difficulty in writing a program or library.</p>

<p>There are two forms of the zero-cost property relevant here:</p>

<ol>
<li><p>Strongly zero-cost: A unit of code generation that does not use
 GC should not pay for it.</p>

<p> For example, in the above example of the string parsing module,
 ideally the code generated for parsing <code>&amp;str</code> values should have
 the same performance characteristics, regardless of whether it is
 linked into a program that uses GC or not.</p></li>
<li><p>Weakly zero-cost: A program that does not use GC should not pay
 for it.</p>

<p> (At worst, one can imagine ensuring this property by compiling
 two different versions of each code unit, and then linking to the
 appropriate one. Hopefully we will not need to resort to that.)</p></li>
</ol>


<p>Strongly zero-cost implies weakly zero-cost, but not vice-versa.</p>

<a name="L.span.id..compositionality..Compositional.GC..span."></a>
<h3><span id="compositionality">Compositional GC</span></h3>

<p>One can use a reference to a gc-allocated object (call it a <code>GcRef</code>)
as the field type in a <code>struct</code>, store it into a <code>Vec&lt;GcRef&gt;</code>, and
in general do anything with it that one can do with a normal Rust value.</p>

<p>Furthermore, one should be able to describe, via a Rust type
definition, the layout of a value allocated on the GC heap, allocate
such values there, and acquire a suitable <code>GcRef</code> to the allocated
object.</p>

<p>To be concrete about this, consider the following program,
which uses a hypothetical <code>make_gc_ref</code> function to move
values into a newly-allocated spot on the GC heap, and returns
a reference to that spot. (In the future one will probably use
the <code>box</code> syntax for this, and rely on type-context to inform
box that this is a GC-allocation.)</p>

<pre><code class="rust">fn demo() {
    let gc_v = {
        let ref_x1 = make_gc_ref("data_one");
        let ref_x2 = make_gc_ref("data_two");
        let v = vec![x1, x1, x2];
        make_gc_ref(v)
    };
    ...
}
</code></pre>

<p>This results in the following diagram:</p>

<p id="target_anchor_demo_composition_1"></p>


<script>
var stack = { id: "cluster_stack", label: "Stack", is_subgraph: true };
var rust_heap = { rankdir:"LR", id: "cluster_rust_heap", label: "Rust Heap", is_subgraph: true };
var gc_heap = { id: "cluster_gc_heap", label: "GC Heap", is_subgraph: true, style: "rounded" };

var x1 = object_record("X1", "<f0> 'data_one'");
var x2 = object_record("X2", "<f0> 'data_two'");

x1.style = "rounded";
x2.style = "rounded";

var gc_v = { id: "gc_v", label: "Gc(V)", shape: "record" };

var v = object_record("V", "<f0> len: 3 | cap: 4 | <f2> ptr: Arr");
v.style = "rounded";
var arr = object_record("Arr", "<f0> Gc(X1) | <f1> Gc(X1) | <f2> Gc(X2)");
arr.color = "blue";

v.f2 = edge_from_to_ports(":f2", ":id", arr);
gc_v.f0 = edge_to_port(":id", v);

arr.f0 = edge_from_to_ports(":f0", ":id", x1);
arr.f1 = edge_from_to_ports(":f1", ":id", x1);
arr.f2 = edge_from_to_ports(":f2", ":id", x2);

stack[0] = gc_v;
rust_heap[0] = arr;
gc_heap[0] = v;
gc_heap[1] = x1;
gc_heap[2] = x2;

var objects = [stack, gc_heap, rust_heap];
post_objects("target_anchor_demo_composition_1", objects, { rankdir:"LR", nodesep:0.2 });
</script>


<p>Here, I have made explicit the heap-allocated backing store <code>Arr</code> (in
blue) for the vector that holds the references to <code>x1</code> and <code>x2</code>.</p>

<p>This shows that if we want GC to reasonably usable (i.e., allow GC
references to be used like other Rust values), we need to support
references out of the GC heap and into the Rust heap, and likewise
references out of the Rust heap and into the GC heap.</p>

<p>It can sometimes be simpler (without necessarily eliminating the
fundamental problem) to just a <code>Box</code> rather than a <code>Vec</code>:</p>

<p id="target_anchor_demo_composition_2"></p>


<script>
var stack = { id: "cluster_stack", label: "Stack", is_subgraph: true };
var rust_heap = { rankdir:"LR", id: "cluster_rust_heap", label: "Rust Heap", is_subgraph: true };
var gc_heap = { id: "cluster_gc_heap", label: "GC Heap", is_subgraph: true, style: "rounded" };
var c = object_record("C", "<f0> Gc(X) | <f1> Box(O)");
c.style = "rounded";
var o = object_record("O", "<f0> Gc(X)");
var x = object_record("X", "<f0> 'data'");
x.style = "rounded";
var gc_a = { id: "gc_c", label: "Gc(C)", shape: "record" };

gc_a.f0 = edge_to_port(":id", c);

o.f0 = edge_from_to_ports(":f0", ":id", x);

c.f0 = edge_from_to_ports(":f0", ":id", x);
c.f1 = edge_from_to_ports(":f1", ":id", o);

stack[0] = gc_a;
rust_heap[0] = o;
gc_heap[0] = c;
gc_heap[1] = x;

var objects = [stack, gc_heap, rust_heap];
post_objects("target_anchor_demo_composition_2", objects, { rankdir:"LR", nodesep:0.2, no_dims: true });
</script>


<p>The program to construct the above picture might look like
this:</p>

<pre><code class="rust">fn demo() {
    struct C(Gc&lt;str&gt;, Box&lt;Gc&lt;str&gt;&gt;);
    let gc_c = {
        let ref_x = make_gc_ref("data");
        let box_o = Box::new(ref_x);
        make_gc_ref(C(ref_x, box_o))
    };
    ...
}
</code></pre>

<p>(The types in the demo program above assume certain features like
allowing <code>Gc&lt;T&gt;</code> for <code>T: ?Sized</code>, which may or may not be reasonable.)</p>

<p>The compositionality constraint may seem obvious (especially if one
starts by assuming that references to gc-allocated objects will be
values of type <code>Gc&lt;T&gt;</code> for arbtrary <code>T</code>).</p>

<p>But using &ldquo;black box&rdquo; GC interop (as described above) would likely
<em>defeat</em> compositionality.  That is why I point out this objective
explicitly.</p>

<a name="L.a.id..precision..Precision..Space-Efficiency...a."></a>
<h3><a id="precision">Precision (Space-Efficiency)</a></h3>

<p>A 100% precise GC is one that knows the type of every object and field
that it encounters, in terms of being able to classify a word of
memory as an integer or a pointer, and also classify whether a given
word of memory is actually usable according to the type of the value
the word is embedded within.</p>

<p>A space-efficient GC, in essence, is one that is eventually able to
reclaim all garbage, without being subverted by particular details of
the host program or the system state.</p>

<p>(Calling a language implementation space-efficient is a reference to
the <a href="http://www.cesura17.net/~will/professional/research/papers/tail.pdf">asymptotic space complexity</a> of a language implementation.  I am
employing the term here because the objective I want to capture is
more general than just precision.)</p>

<p>A <a href="/blog/2015/10/27/gc-and-rust-part-0-how-does-gc-work/#conservative-gc">conservative GC</a> lacks precision. In other words,
a precise GC is more space-efficient than a conservative GC: There
exists a program that will exhibit worse (asymptotic) space
performance atop a conservative GC than it would atop a precise GC.</p>

<p>We would like Rust to be able to interoperate with 100% precise
collectors.</p>

<p>Ideally, we would also like to be able to interoperate with collectors
that do not support <a href="/blog/2015/10/27/gc-and-rust-part-0-how-does-gc-work/#pinning-support">pinning</a>.</p>

<p>Finally, we would like to ensure that the heap patterns associated
with <a href="#compositionality">Compositionality</a> do not cause garbage to go unreclaimed.</p>

<ul>
<li>Note that a precise GC that treats <em>all</em> objects on the &ldquo;Rust Heap&rdquo;
as roots is not very space-efficient: it will fail to collect
cyclic garbage structure like the below.</li>
</ul>


<p id="target_anchor_demo_garbage_cycle_thru_rust_heap"></p>


<script>
var stack = { id: "cluster_stack", label: "Stack", is_subgraph: true };
var rust_heap = { rankdir:"LR", id: "cluster_rust_heap", label: "Rust Heap", is_subgraph: true };
var gc_heap = { id: "cluster_gc_heap", label: "GC Heap", is_subgraph: true, style: "rounded" };

var local_a = { id: "local_a", label: "a", shape: "record" };

var a = object_record("A", "<f0> Some(Gc(B)) | <f1> None");
a.style = "rounded";
var b = object_record("B", "<f0> None | <f1> None");
b.style = "rounded";
var c = object_record("C", "<f0> Some(Gc(B)) | <f1> Some(Box(O))");
c.style = "rounded";
var o = object_record("O", "<f0> Gc(C)");

a.f0 = edge_from_to_ports(":f0", ":id:n", b);

c.f0 = edge_from_to_ports(":f0", ":id", b);
c.f1 = edge_from_to_ports(":f1:s", ":id", o);
o.f0 = edge_from_to_ports(":f0", ":id", c);

stack[1] = local_a;
local_a.ref = edge_to_port(":id", a);

gc_heap[0] = a;
gc_heap[1] = b;
gc_heap[2] = c;
rust_heap[0] = o;

var objects = [stack, gc_heap, rust_heap];
post_objects("target_anchor_demo_garbage_cycle_thru_rust_heap", objects, { rankdir:"LR", nodesep:0.2, no_dims: true});
</script>


<p>In the above diagram, &ldquo;C&rdquo; and &ldquo;O&rdquo; are unreachable by the program
itself (&ldquo;O&rdquo; is owned by the gc-allocated &ldquo;C&rdquo;), but if you treat all
objects in the Rust Heap as roots, then it will classify &ldquo;O&rdquo; as a
root, and &ldquo;C&rdquo; will never be reclaimed.</p>

<p>This is why compositionality can interact with space-efficiency.
Allowing gc-allocated objects to own data allocated on the Rust heap,
while also allowing references to gc-allocated objects to be stored in
values on the Rust heap, then you will encounter cyclic structure like
this. (This was the design bug that led me to withdraw my &ldquo;Take II&rdquo;
<a href="https://github.com/rust-lang/rfcs/pull/244">allocator RFC</a>.)</p>

<a name="Conclusion"></a>
<h2>Conclusion</h2>

<p>This post was dedicated to identifying criteria that we would
like GC-integration with Rust to satisfy.</p>

<p>Next up: Why is it hard to satisfy the above criteria simultaneously?</p>
]]></content>
  </entry>
  
</feed>
